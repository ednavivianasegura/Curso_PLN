{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ednavivianasegura/Curso_PLN/blob/main/Curso_PLN_UR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce59cdd3-f22c-4cc9-ba35-b8fbe5ce3d57",
      "metadata": {
        "id": "ce59cdd3-f22c-4cc9-ba35-b8fbe5ce3d57"
      },
      "source": [
        "***\n",
        "<center>\n",
        "<img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/Portada.png?raw=1\" alt=\"portada\" width=\"80%\" height=\"80%\">  \n",
        "</center>\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# ¬øQu√© es el procesamiento del lenguale natural (PLN)?\n",
        "***"
      ],
      "metadata": {
        "id": "sSrdCkOi3Ww2"
      },
      "id": "sSrdCkOi3Ww2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/PLN1.png?raw=1\" alt=\"PLN1\" width=\"98%\" height=\"98%\">  \n",
        "</center>\n"
      ],
      "metadata": {
        "id": "N6btWGYwC95M"
      },
      "id": "N6btWGYwC95M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/PLN2.png?raw=1\" alt=\"PLN2\" width=\"98%\" height=\"98%\">  \n",
        "</center>\n"
      ],
      "metadata": {
        "id": "i4jyYCTXC9i5"
      },
      "id": "i4jyYCTXC9i5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**¬°Comencemos!**\n",
        "***"
      ],
      "metadata": {
        "id": "Srd8cQihiGZF"
      },
      "id": "Srd8cQihiGZF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contenido\n",
        "\n",
        "\n",
        "\n",
        "1.   Estad√≠stica descriptiva univariante\n",
        "\n",
        "    *   Tablas de frecuencias.\n",
        "    *   Gr√°ficos unidimensionales.\n",
        "    *   Medidas de una variable cuantitativa:\n",
        "        * de posici√≥n:            \n",
        "            * media aritm√©tica\n",
        "            * mediana y cuantiles\n",
        "            * moda\n",
        "        * de dispersi√≥n abolsuta:\n",
        "            * varianza y desviaci√≥n t√≠pica\n",
        "    * An√°lisis de frecuencias de n-gramas.\n",
        "\n",
        "2.   Introducci√≥n a la Teor√≠a de la Probabilidad\n",
        "    *   Distribuci√≥n de probabilidad\n",
        "    *   Variable aleatoria\n",
        "    *   Probabilidad condicionada. Teorema de bayes.\n",
        "3.   Inferencia estad√≠stica\n",
        "    *   Conceptos b√°sicos.\n",
        "    *   Casos de uso.\n",
        "\n",
        "4.   Estad√≠stica multivariante\n",
        "    *   Correlaci√≥n.\n",
        "    *   Regresi√≥n.\n",
        "    *   Clasificaci√≥n: Clasificador bayesiano ingenuo.\n",
        "5.  Modelizaci√≥n PLN\n",
        "    * Modelos de lenguaje.\n",
        "    * Modelos de etiquetado gramatical.\n",
        "    * Modelos de aprendizaje autim√°tico para el PLN.  "
      ],
      "metadata": {
        "id": "I7H3OSXp6kja"
      },
      "id": "I7H3OSXp6kja"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "\n",
        "# 1. Estad√≠stica descriptiva univariante\n",
        "\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/desc-univariante.png?raw=1\" alt=\"descriptiva\" width=\"50%\" height=\"50%\">  \n",
        "</center>\n",
        "\n",
        "***\n",
        "***"
      ],
      "metadata": {
        "id": "TURmkxgx0D6J"
      },
      "id": "TURmkxgx0D6J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¬øQu√© es la estad√≠stica descriptiva?:\n",
        "\n",
        "La **Estad√≠stica Descriptiva** es una rama de la estad√≠stica que se enfoca en organizar, resumir y presentar de manera significativa un conjunto de datos para facilitar su comprensi√≥n. Su objetivo principal es describir las caracter√≠sticas principales de un conjunto de datos, como la tendencia central (media, mediana, moda), las medidas no centrales (cuantiles), la dispersi√≥n (desviaci√≥n est√°ndar, rango intercuart√≠lico), la forma de la distribuci√≥n, entre otros aspectos relevantes. A trav√©s de herramientas como tablas, gr√°ficos y medidas estad√≠sticas, la Estad√≠stica Descriptiva permite visualizar y analizar patrones y comportamientos presentes en los datos.\n",
        "\n",
        "Por otro lado, una ***variable en estad√≠stica*** es una caracter√≠stica o atributo que puede tomar diferentes valores en un conjunto de datos.\n",
        "\n",
        "Es la codificaci√≥n de una caracter√≠stica de una poblaci√≥n. Lo habitual es disponer de la informaci√≥n de una o varias variables en una muestra que sea parte de la poblaci√≥n.\n",
        "\n",
        "Existen, a grandes rasgos, dos tipos de variables:\n",
        "\n",
        "*   Variables num√©ricas\n",
        "  *   Discretas (cardinalidad finita o numerable): es un tipo de variable cuantitativa que solo puede tomar valores aislados, generalmente enteros, que se obtienen mediante un conteo.\n",
        "  \n",
        "        **Por ejemplo**, si estamos analizando la longitud de los p√°rrafos en un texto, la cantidad de palabras en cada p√°rrafo ser√≠a una variable discreta, ya que solo puede tomar valores enteros y no fraccionarios. Podemos contar el n√∫mero exacto de palabras en cada p√°rrafo, lo que nos da una medida discreta y espec√≠fica.\n",
        "\n",
        "  *   Continuas (cardinalidad infinita o  no numerable): es un tipo de variable cuantitativa que puede tomar cualquier valor dentro de un intervalo, que se obtienen mediante una medici√≥n. Admite valores intermedios o decimales.\n",
        "        \n",
        "        **Por ejemplo**, si queremos analizar la frecuencia de la palabra \"tecnolog√≠a\" en un art√≠culo, esta variable ser√≠a continua, ya que puede tomar valores en un rango infinito y no est√° limitada a valores espec√≠ficos. Podemos tener 1.5 repeticiones por p√°rrafo, 2.3 repeticiones por p√°gina, etc., lo que nos da una medida continua y no necesariamente entera.\n",
        "\n",
        "*   Variables categ√≥ricas: es un tipo de variable que describe cualidades de la poblaci√≥n.\n",
        "  *   Las variables ordinales: se pueden ordenar linealmente.\n",
        "  \n",
        "        Ejemplo: categorizar las palabras seg√∫n su longitud en diferentes grupos ordenados, como:\n",
        "        * Palabras cortas (1-3 caracteres)\n",
        "        * Palabras de longitud media (4-6 caracteres)\n",
        "        * Palabras largas (7 o m√°s caracteres)\n",
        "\n",
        "  *   Variables nominales: establecen categor√≠as que no est√°n intr√≠nsecamente ordenadas.\n",
        "  \n",
        "        Ejemplo: categor√≠as gramaticales, como sustantivos, verbos, adjetivos, adverbios, pronombres, preposiciones, conjunciones, entre otros.\n",
        "  \n",
        "  En sentido estricto, las cadenas de texto procedentes de un lenguaje son variables ordinales. Sin embargo, podr√≠amos establecer el texto como un tipo de variable por s√≠ misma, ya que tiene sus particularidades.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5n-SABJOu2Yo"
      },
      "id": "5n-SABJOu2Yo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Notaci√≥n:\n",
        "***\n",
        "\n",
        "Establecemos la siguiente notaci√≥n para lo que sigue.\n",
        "* De una variable $X$ tenemos $N$ datos (casos) que pueden ser repetidos o no: $ùëã_1,ùëã_2,‚Ä¶,ùëã_ùëÅ$ (en may√∫sculas).\n",
        "* Si solo indicamos los valores distintos entre s√≠: $ùë•_1,ùë•_2,‚Ä¶,ùë•_ùêæ$ (en min√∫sculas) cada uno con su respectiva frecuencia $ùëõ_1,ùëõ_2,‚Ä¶,ùëõ_ùêæ$.\n",
        "\n",
        "\n",
        "**Notas:**\n",
        "$ùëÅ=ùëõ_1+ùëõ_2+‚ãØ+ùëõ_ùêæ=‚àëùëõ_ùëñ$ representa el n√∫mero de casos (el tama√±o de la muestra).\n",
        "\n",
        "$ùêæ$ representa el n√∫mero de valores distintos entre s√≠ de la variable $ùëã$.\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "9humrD6e8XFR"
      },
      "id": "9humrD6e8XFR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo de conjunto de datos:\n",
        "\n",
        "Conjunto de datos de *Amazon Fine Food Reviews de¬†Kaggle*¬†(archivo disponible en [Reviews.csv](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)).\n",
        "\n",
        "Cuenta con un total de ***568454*** rese√±as de productos de ***Amazon***.\n",
        "\n",
        "En este proyecto, para aligerar la intensidad computacional, utilizaremos una *muestra* obtenida de forma aleatoria, que contiene ***45476*** rese√±as.\n",
        "\n",
        "Recurriremos a este conjunto datos reducido para ilustrar muchos de los ejemplos que realizaremos durante el curso.\n",
        "\n",
        "Las variables de este conjunto de datos son:\n",
        "\n",
        "* ProductId - Identificador del producto.\n",
        "* ProfileName - nombre del usuario.\n",
        "* HelpfulnessNumerator - fracci√≥n de usuarios a los que les result√≥ √∫til la rese√±a.\n",
        "* Score ‚Äì clasificaci√≥n del producto.\n",
        "* Time -  hora de la rese√±a.\n",
        "* Summary ‚Äì Breve resumen de la rese√±a.\n",
        "* Text ‚Äì Rese√±a completa del art√≠culo.\n",
        "\n"
      ],
      "metadata": {
        "id": "3kQUQRZOjSWE"
      },
      "id": "3kQUQRZOjSWE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aqu√≠ comenzamos con Python:\n"
      ],
      "metadata": {
        "id": "KUAyJzgFFpEc"
      },
      "id": "KUAyJzgFFpEc"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Librer√≠as necesarias**{ display-mode: \"form\" }\n",
        "\n",
        "!python -m spacy download es_core_news_sm\n",
        "import os #Es una biblioteca est√°ndar que proporciona una interfaz para interactuar con el sistema operativo en el que se est√° ejecutando el programa Python. Permite realizar una variedad de operaciones relacionadas con el sistema operativo, como manipular archivos y directorios, obtener informaci√≥n sobre el entorno del sistema, realizar operaciones de gesti√≥n de procesos y manipular rutas de archivos de manera independiente del sistema operativo.\n",
        "import nltk #Natural Language Toolkit\n",
        "\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stopword_en = nltk.corpus.stopwords.words('english')\n",
        "stopword_sp = nltk.corpus.stopwords.words('spanish')\n",
        "\n",
        "import networkx as nx #Para la creaci√≥n, manipulaci√≥n y estudio de la estructura, din√°mica y funciones de redes complejas.\n",
        "\n",
        "import spacy #Proporciona herramientas y recursos para realizar tareas relacionadas con el procesamiento del lenguaje natural, como tokenizaci√≥n, an√°lisis morfol√≥gico, an√°lisis sint√°ctico, reconocimiento de entidades nombradas y muchas otras.\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "from scipy.stats import norm\n",
        "\n",
        "import wordcloud # Es una herramienta que permite crear visualizaciones de nubes de palabras a partir de un texto dado\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import matplotlib.pyplot as plt #Es una librer√≠a que proporciona una amplia gama de herramientas para crear gr√°ficos est√°ticos, interactivos y animados. Es una de las bibliotecas m√°s utilizadas y populares para la visualizaci√≥n de datos en Python debido a su flexibilidad, potencia y facilidad de uso.\n",
        "import seaborn as sns #Es una biblioteca de visualizaci√≥n de datos para Python que se construye sobre Matplotlib y proporciona una interfaz de alto nivel para crear gr√°ficos estad√≠sticos atractivos y informativos. Seaborn est√° dise√±ado espec√≠ficamente para trabajar con estructuras de datos de Pandas y facilita la creaci√≥n de visualizaciones complejas con unas pocas l√≠neas de c√≥digo.\n",
        "import pandas as pd  #Es una herramienta de an√°lisis y manipulaci√≥n de datos\n",
        "import  math # Es una librer√≠a que proporciona funciones y constantes matem√°ticas predefinidas para realizar operaciones y c√°lculos matem√°ticos avanzados.\n",
        "import numpy as np # Es utilizada principalmente para realizar c√°lculos num√©ricos y manipular matrices y arreglos multidimensionales de manera eficiente.\n",
        "\n",
        "import random #proporciona funciones para generar n√∫meros aleatorios y realizar operaciones relacionadas con la aleatoriedad\n",
        "from statistics import median # proporciona funciones para realizar c√°lculos estad√≠sticos b√°sicos sobre conjuntos de datos num√©ricos\n",
        "import re #proporciona operaciones para trabajar con expresiones regulares, que son patrones utilizados para hacer coincidir secuencias de caracteres en texto. Las expresiones regulares son extremadamente √∫tiles para buscar, extraer y manipular texto de manera flexible y eficiente.\n",
        "import unicodedata #proporciona funciones para trabajar con caracteres Unicode. Unicode es un est√°ndar de codificaci√≥n de caracteres que asigna un n√∫mero √∫nico a cada car√°cter utilizado en la mayor√≠a de los sistemas de escritura del mundo, incluidos caracteres alfab√©ticos, num√©ricos, de puntuaci√≥n, s√≠mbolos y caracteres especiales.\n",
        "import collections #proporciona alternativas especializadas a los contenedores de datos incorporados de Python, como listas, diccionarios, conjuntos y tuplas.\n",
        "\n"
      ],
      "metadata": {
        "id": "_DzrAQ8kjhyN"
      },
      "id": "_DzrAQ8kjhyN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Clonar carpeta GitHub** (Para acceder al dataset) { form-width: \"5%\", display-mode: \"form\" }\n",
        "# Clona el repositorio\n",
        "try:\n",
        "    !git clone https://github.com/ednavivianasegura/Curso_PLN.git\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Cambiar al directorio \"Curso_PLN\"\n",
        "os.chdir(\"Curso_PLN\")"
      ],
      "metadata": {
        "id": "BUy1MgJqqtVA"
      },
      "id": "BUy1MgJqqtVA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad138970-7a94-490a-9099-765d22cfc5c1",
      "metadata": {
        "id": "ad138970-7a94-490a-9099-765d22cfc5c1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Funciones predise√±adas necesarias durante el proceso\n",
        "#Estas funciones se explican posteriormente\n",
        "\n",
        "def group_by_intervals(df, column, num_bins):\n",
        "    bin_width = (df[column].max() - df[column].min()) / num_bins\n",
        "    bins, bin_edges = pd.cut(df[column], bins=num_bins, include_lowest=True, right=False, retbins=True)\n",
        "\n",
        "    # Generar etiquetas para los intervalos basados en los l√≠mites de los intervalos\n",
        "    labels = [f\"[{int(round(bin_edges[i],0))}-{int(round(bin_edges[i+1],0))})\" for i in range(len(bin_edges)-1)]\n",
        "    bins = pd.cut(df[column], bins=num_bins, include_lowest=True, right=False, retbins=True, labels=labels)[0]\n",
        "    return bins\n",
        "\n",
        "\n",
        "def marca_de_clase(intervalo):\n",
        "    limite_inferior, limite_superior = map(float, intervalo.strip(\"[]()\").split('-'))\n",
        "    return (limite_inferior + limite_superior) / 2\n",
        "\n",
        "\n",
        "def calcular_mediana(datos):\n",
        "    # Ordenar los datos\n",
        "    datos_ordenados = sorted(datos)\n",
        "    n = len(datos_ordenados)\n",
        "\n",
        "    # Calcular la mediana\n",
        "    if n % 2 == 1:\n",
        "        # Si la cantidad de datos es impar\n",
        "        mediana = datos_ordenados[n // 2]\n",
        "        print(\"n es impar\")\n",
        "    else:\n",
        "        # Si la cantidad de datos es par\n",
        "\n",
        "        indice_medio1 = n // 2 - 1\n",
        "        indice_medio2 = n // 2\n",
        "\n",
        "        print(f\"n es par, por lo tanto:\\nla posici√≥n 1 es {datos_ordenados[indice_medio1]} y la posici√≥n 2 es {datos_ordenados[indice_medio2]}\")\n",
        "        mediana = (datos_ordenados[indice_medio1] + datos_ordenados[indice_medio2]) / 2\n",
        "    return mediana\n",
        "\n",
        "def limpiar_texto(texto,idioma='spanish'):\n",
        "    # Convertir el texto a min√∫sculas\n",
        "    texto = texto.lower()\n",
        "    texto = texto.replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u').replace('√º', 'u')  # Quitar tildes\n",
        "    texto = texto.replace(',', '')  # Quitar comas\n",
        "    texto = texto.replace('.', '')  # Quitar puntos\n",
        "    # Eliminar caracteres especiales y n√∫meros\n",
        "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
        "    # Tokenizar el texto en palabras\n",
        "    palabras = word_tokenize(texto, language=idioma)\n",
        "    # Eliminar stopwords\n",
        "    if idioma == \"english\":\n",
        "        stopwords = set(stopword_en)\n",
        "    elif idioma == \"spanish\":\n",
        "        stopwords = set(stopword_sp)\n",
        "    palabras = [palabra for palabra in palabras if palabra not in stopwords]\n",
        "    # Eliminar acentos\n",
        "    palabras = [unicodedata.normalize('NFKD', palabra).encode('ASCII', 'ignore').decode('utf-8') for palabra in palabras]\n",
        "    # Unir las palabras nuevamente en un solo texto\n",
        "    texto_limpio = ' '.join(palabras)\n",
        "    return texto_limpio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1aac4de-49c6-41cc-9750-03b7d316ca0f",
      "metadata": {
        "id": "b1aac4de-49c6-41cc-9750-03b7d316ca0f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Importar** conjunto de datos\n",
        "df = pd.read_csv('Reviews.csv')\n",
        "#muestra: N\n",
        "N=df.shape[0]\n",
        "print(f\"Informaci√≥n disponible en el dataframe:\\n{list(df.columns)}\\nEl dataframe contiene {N} rese√±as\\n\")\n",
        "display(df.loc[:,['Id', 'ProductId', 'ProfileName', 'Score', 'Time', 'Summary', 'Text']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para complementar la informaci√≥n proporcionada por el conjunto de datos, se crean dos variables adicionales, una llamada *Longitud_Texto* que cuenta el n√∫mero de palabras en cada rese√±a y otra, llamada *Num_Palabras_Unicas* que cuenta el n√∫mero de palabras √∫nicas (es decir sin que se repitan) en cada rese√±a."
      ],
      "metadata": {
        "id": "L0jmnPxuFLXy"
      },
      "id": "L0jmnPxuFLXy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fca7310-2e89-4401-af5e-c3567e11b5d4",
      "metadata": {
        "id": "5fca7310-2e89-4401-af5e-c3567e11b5d4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Crear dos variables nuevas\n",
        "# Creamos una nueva variable que contiene el n√∫mero de palabras que componene\n",
        "# Contar la longitud de las palabras en la columna 'texto'\n",
        "df['Longitud_Texto'] = df['Text'].apply(lambda x: len(x.split()))\n",
        "# Calcula el n√∫mero de palabras √∫nicas en la columna 'Text'\n",
        "df['Num_Palabras_Unicas'] = df['Text'].apply(lambda x: len(set(x.split())))\n",
        "\n",
        "display(df.loc[:,['Id','Score', 'Summary', 'Text','Longitud_Texto','Num_Palabras_Unicas']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4422bf7e-3ff6-4841-aafd-8cb875bd3403",
      "metadata": {
        "id": "4422bf7e-3ff6-4841-aafd-8cb875bd3403"
      },
      "source": [
        "***\n",
        "## TABLA DE FRECUENCIAS\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambi√©n denominadas tabulaciones, resumen los datos de una variable.\n",
        "\n",
        "Para cada valor observado $ùë•_{ùëñ}$, en la tabla se indica:\n",
        "* La frecuencia absoluta $ùëõ_{ùëñ}$ es el n√∫mero de veces que se da el valor $ùë•_{ùëñ}$.\n",
        "* La frecuencia relativa $ùëì_{ùëñ}=\\frac{ùëõ_{ùëñ}}{ùëÅ}$ donde $ùëÅ$ es el n√∫mero de casos. Notas:\n",
        "    * $0 < f_{ùëñ} \\leq1$, representa la proporci√≥n de $ùë•_{ùëñ}$;\n",
        "    * se suele expresar en porcentaje: $ùëì_{ùëñ}\\times100$%.\n",
        "\n",
        "Si la variable es num√©rica (tambi√©n llamada cuantitativa) o si es ordinal (esto es, sus valores se pueden ordenar), ordenamos los valores observados de manera creciente $ùë•_{1}<ùë•_{2}<‚ãØ$ y tambi√©n indicamos:\n",
        "* La frecuencia absoluta acumulada $ùëÅ_{ùëñ}=ùëõ_{1}+ùëõ_{2}+‚ãØ+ùëõ_{ùëñ}$ es el n√∫mero de casos menores o iguales que $ùë•_{ùëñ}$.\n",
        "* La frecuencia relativa acumulada $ùêπ_{ùëñ}=ùëì_{1}+ùëì_{2}+‚ãØ+ùëì_{ùëñ}$ . Notas:\n",
        "    * $0 < F_{ùëñ} \\leq1$, representa la proporci√≥n de valores menores o iguales que $ùë•_{ùëñ}$;\n",
        "    * tambi√©n se suele expresar en tanto por ciento: $ùêπ_{ùëñ}\\times100$%.\n",
        "\n",
        "***\n",
        "**Ejemplo base**:\n",
        "***\n",
        "\n",
        "Crear paso a paso la tabla de frecuencias si tenemos un conjunto de edades de 10 personas:\n",
        "\n",
        "\\[ 25, 30, 35, 40, 45, 25, 35, 30, 35, 40 \\]"
      ],
      "metadata": {
        "id": "sBER9zdtGDCE"
      },
      "id": "sBER9zdtGDCE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04cab4e4-a39f-4371-bd52-27e664180b0c",
      "metadata": {
        "id": "04cab4e4-a39f-4371-bd52-27e664180b0c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Ejercicio:** Crear la tabla de frecuencias de la variable *longitud de palabras*:\n",
        "\n",
        "#Creamos la tabla de frecuencias de la variable \"longitud de palabras\":\n",
        "\n",
        "frecuencias_long = df['Longitud_Texto'].value_counts()\n",
        "frecuencias_long = frecuencias_long.sort_index()\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "frecuencias_relativas = frecuencias_long / len(df)\n",
        "\n",
        "# Calcular las frecuencias acumuladas\n",
        "frecuencias_acumuladas = frecuencias_long.cumsum()\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "frecuencias_relativas_acum = frecuencias_acumuladas / len(df)\n",
        "\n",
        "# Crear DataFrame con las frecuencias\n",
        "tabla_frecuencias = pd.DataFrame({\n",
        "    'x_i': frecuencias_long.index,\n",
        "    'n_i': frecuencias_long.values,\n",
        "    'f_i': frecuencias_relativas.values,\n",
        "    'N_i':frecuencias_acumuladas.values,\n",
        "    'F_i':frecuencias_relativas_acum.values\n",
        "})\n",
        "print(\"Tabla de frecuencias de la columna\\n'Longitud del texto\\n(n√∫mero de palabras dentro de cada rese√±a)':\\n\")\n",
        "display(tabla_frecuencias)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d95c96a-e15b-4544-98a0-b6f5acb53300",
      "metadata": {
        "id": "3d95c96a-e15b-4544-98a0-b6f5acb53300"
      },
      "source": [
        "### TABLA DE FRECUECIAS POR INTERVALOS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si una variable cuenta con una gran cantidad de valores distintos, como es el caso de la variable *Longitud del texto*, lo habitual es resumirla en una una tabla de frecuencias reducida por intervalos. En este caso la frecuencia, $ùëõ_ùëñ$, es el n√∫mero de casos cuyos valores se encuentran en el ùëñ-√©simo intervalo.\n",
        "\n",
        "***Intervalos***:\n",
        "Cada intervalo est√° determinado por sus l√≠mites. Esto es, el intervalo $ùëé‚ü∑ùëè$ representa los valores comprendidos entre $ùëé$ y $ùëè$.\n",
        "\n",
        "\n",
        "Si se requiere determinar la ubicaci√≥n de los l√≠mites, estos pueden ser referidos con una notaci√≥n m√°s completa. Generalmente se utilizan intervalos abiertos por la izquierda y cerrados por la derecha: $(ùëé,ùëè]$. Esto es, incluye los valores comprendidos entre $ùëé$ y $ùëè$, $ùëè$ incluido y $ùëé$ excluido.\n",
        "\n",
        "La amplitud de intervalo $ùëé‚ü∑ùëè$ es $ùëè‚àíùëé$, que tambi√©n es la amplitud de los intervalos $(ùëé,ùëè]$ y $[ùëé,ùëè)$ (este √∫ltimo intervalo representa los valores mayores o iguales que $ùëé$ y menores que $ùëè$).\n",
        "\n",
        "En las tablas de frecuencias los intervalos pueden ser de amplitud constante (m√°s c√≥modo) o variable.\n",
        "\n",
        "La densidad de frecuencia de un intervalo es la raz√≥n de su frecuencia absoluta sobre su amplitud. El intervalo $ùëñ$ con frecuencia absoluta $ùëõ_ùëñ$ y amplitud $ùëé_ùëñ$ tiene una densidad de frecuencia $‚Ñé_ùëñ=ùëõ_ùëñ/ùëé_ùëñ$.\n",
        "\n",
        "\n",
        "En las variables cuantitativas la **marca de clase** de un intervalo es el valor concreto de la variable que representa cada intervalo, generalmente se toma el punto medio del intervalo. El punto medio de $(ùëé,ùëè]$ es: $(a+b)/2$. Para calcular medidas cuantitativas de una variable reducida por intervalos se usan las marcas de clase.\n",
        "\n",
        "***\n",
        "**Ejemplo base**:\n",
        "***\n",
        "\n",
        "Crear la tabla de frecuencias por intervalo si tenemos un conjunto de edades de 17 personas:\n",
        "\n",
        "\\[51,58,40,45,49,20,22,25,28,28, 30,30,30,38,34,36,39\\]\n"
      ],
      "metadata": {
        "id": "SxCYYKEhD2Bi"
      },
      "id": "SxCYYKEhD2Bi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479fb3e4-426d-4b3d-b09d-5b96846ee54f",
      "metadata": {
        "id": "479fb3e4-426d-4b3d-b09d-5b96846ee54f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Ejercicio**: Resumimos los valores de la variable *Longitud del texto* por los intervalos indicados.\n",
        "\n",
        "print(\"--------------------------------------------------------------------\\nTras hacer el recuento obtenemos la siguiente tabla.\\n--------------------------------------------------------------------\\n\")\n",
        "# Calcular los grupos usando la funci√≥n creada group_by_sturges\n",
        "df['intervalo'] = group_by_intervals(df, 'Longitud_Texto',10)\n",
        "\n",
        "# Calcular la tabla de frecuencias de la columna 'Grupo'\n",
        "frecuencias_grupo = df['intervalo'].value_counts()\n",
        "frecuencias_grupo = frecuencias_grupo.sort_index()\n",
        "print(\"\\nFrecuencias usando el m√©todo de sturges\\n\")\n",
        "\n",
        "# Calcular la marca de clase para cada intervalo\n",
        "MarcaDeClase = list(map(marca_de_clase, list(frecuencias_grupo.index)))\n",
        "\n",
        "# Crear DataFrame con las frecuencias\n",
        "tabla_frecuencias_Longitud_Texto = pd.DataFrame({\n",
        "    'x_i': frecuencias_grupo.index,\n",
        "    'n_i': frecuencias_grupo.values,\n",
        "    'MarcaDeClase':MarcaDeClase})\n",
        "\n",
        "print(tabla_frecuencias_Longitud_Texto)\n",
        "# print(frecuencias_grupo.index)\n",
        "# print(MarcaDeClase)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que hay varios intervalos con muy poca densidad de frecuencia, por lo que podemos unir los intervalos consecutivos en uno solo:"
      ],
      "metadata": {
        "id": "kIgXhqc4GODG"
      },
      "id": "kIgXhqc4GODG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4563615-7c7d-4c9d-88a1-b386dd467417",
      "metadata": {
        "id": "a4563615-7c7d-4c9d-88a1-b386dd467417",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Unir los grupos con poca frecuencia en uno solo:\n",
        "# agrupar los √∫ltimos grupos en uno solo:\n",
        "\n",
        "lista=[ '[954-1143)', '[1143-1332)', '[1332-1522)',\n",
        "                  '[1522-1712)', '[1712-1903)']\n",
        "\n",
        "# Reemplazar los valores en la columna 'columna_original' con \"954-1903\" si coinciden con los valores de la lista\n",
        "df['intervalo'] = df['intervalo'].replace(lista, '[954-1903')\n",
        "\n",
        "# Calcular la tabla de frecuencias de la columna 'Grupo'\n",
        "frecuencias_grupo = df['intervalo'].value_counts()\n",
        "frecuencias_grupo = frecuencias_grupo.sort_index()\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "frecuencias_relativas_gr = frecuencias_grupo / len(df)\n",
        "\n",
        "# Calcular las frecuencias acumuladas\n",
        "frecuencias_acumuladas_gr = frecuencias_grupo.cumsum()\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "frecuencias_relativas_acum_gr = frecuencias_acumuladas_gr / len(df)\n",
        "\n",
        "# Crear DataFrame con las frecuencias\n",
        "tabla_frecuencias_gr = pd.DataFrame({\n",
        "    'x_i': frecuencias_grupo.index,\n",
        "    'n_i': frecuencias_grupo.values,\n",
        "    'f_i': frecuencias_relativas_gr.values,\n",
        "    'N_i':frecuencias_acumuladas_gr.values,\n",
        "    'F_i':frecuencias_relativas_acum_gr.values\n",
        "})\n",
        "\n",
        "\n",
        "print(\"Tabla de frecuencias agrupadas por intervalo de la columna\\n'Longitud del texto':\\n\")\n",
        "display(tabla_frecuencias_gr)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ejemplo 2: Tabla de frecuencia del n√∫mero de palabras √∫nicas { display-mode: \"form\" }\n",
        "#Creamos la tabla de frecuencias de la variable \"Num_Palabras_Unicas\":\n",
        "\n",
        "frecuencias_long_unic = df['Num_Palabras_Unicas'].value_counts()\n",
        "frecuencias_long_unic = frecuencias_long_unic.sort_index()\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "frecuencias_relativas_unic = frecuencias_long_unic / len(df)\n",
        "\n",
        "# Calcular las frecuencias acumuladas\n",
        "frecuencias_acumuladas_unic = frecuencias_long_unic.cumsum()\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "frecuencias_relativas_acum_unic = frecuencias_relativas_unic / len(df)\n",
        "\n",
        "# Crear DataFrame con las frecuencias\n",
        "tabla_frecuencias_unic = pd.DataFrame({\n",
        "    'x_i': frecuencias_long_unic.index,\n",
        "    'n_i': frecuencias_long_unic.values,\n",
        "    'f_i': frecuencias_relativas_unic.values,\n",
        "    'N_i':frecuencias_acumuladas_unic.values,\n",
        "    'F_i':frecuencias_relativas_acum_unic.values\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "# Calcular los grupos usando la funci√≥n creada group_by_sturges\n",
        "df['intervalo'] = group_by_intervals(df, 'Num_Palabras_Unicas',10)\n",
        "\n",
        "# Calcular la tabla de frecuencias de la columna 'Grupo'\n",
        "frecuencias_grupo_unic = df['intervalo'].value_counts()\n",
        "frecuencias_grupo_unic = frecuencias_grupo_unic.sort_index()\n",
        "print(\"\\nFrecuencias usando el m√©todo de sturges en conteo √∫nico\\n\")\n",
        "\n",
        "# Calcular la marca de clase para cada intervalo\n",
        "MarcaDeClase_unic = list(map(marca_de_clase, list(frecuencias_grupo_unic.index)))\n",
        "\n",
        "# Crear DataFrame con las frecuencias\n",
        "tabla_frecuencias_Num_Palabras_Unicas = pd.DataFrame({\n",
        "    'x_i': frecuencias_grupo_unic.index,\n",
        "    'n_i': frecuencias_grupo_unic.values,\n",
        "    'MarcaDeClase':MarcaDeClase_unic})\n",
        "\n",
        "print(tabla_frecuencias_Num_Palabras_Unicas)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_vNsSqA88eih"
      },
      "id": "_vNsSqA88eih",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13412d14-89bc-4f2c-a7fd-ce2620e3492f",
      "metadata": {
        "id": "13412d14-89bc-4f2c-a7fd-ce2620e3492f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Ejercicio:** Resumimos los valores de la variable *Score*, realizando los conteos necesarios\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\\nTras hacer el recuento obtenemos la siguiente tabla.\\n--------------------------------------------------------------------------------\")\n",
        "# Calcular la tabla de frecuencias de la columna 'Score'\n",
        "frecuencias_score = df['Score'].value_counts()\n",
        "frecuencias_score = frecuencias_score.sort_index()\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "frecuencias_relativas = frecuencias_score / len(df)\n",
        "\n",
        "# Calcular las frecuencias acumuladas\n",
        "frecuencias_acumuladas = frecuencias_score.cumsum()\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "frecuencias_relativas_acum = frecuencias_acumuladas / len(df)\n",
        "\n",
        "\n",
        "# Crear DataFrame con las frecuencias\n",
        "tabla_frecuencias = pd.DataFrame({\n",
        "    'x_i': frecuencias_score.index,\n",
        "    'n_i': frecuencias_score.values,\n",
        "    'f_i': frecuencias_relativas.values,\n",
        "    \"N_i\":frecuencias_acumuladas.values,\n",
        "    \"F_i\":frecuencias_relativas_acum.values\n",
        "})\n",
        "display(tabla_frecuencias)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa la tabla de frecuencias del puntaje (score) de las rese√±as de Amazon y contesta a las siguientes preguntas:\n",
        "\n",
        "\n",
        "1.   ¬øCu√°ntas rese√±as fueron valoradas con 4?\n",
        "2.   ¬øCu√°ntas rese√±as fueron valoradas con menos de 3?\n",
        "3.   ¬øCu√°ntas rese√±as tienen 4 o menos de valoraci√≥n?\n",
        "4.   ¬øCu√°ntas rese√±as tienen m√°s de 4 puntos de valoraci√≥n?\n",
        "5.   ¬øCu√°l es la proporci√≥n de rese√±as con puntaje igual a 3?\n",
        "6.   ¬øCu√°l es la proporci√≥n de rese√±as menores a 3?\n",
        "7.   ¬øCu√°l es la proporci√≥n de rese√±as mayores de 2?\n",
        "\n"
      ],
      "metadata": {
        "id": "KjHoqW30G9OT"
      },
      "id": "KjHoqW30G9OT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n"
      ],
      "metadata": {
        "id": "EznjlYdeJGyY"
      },
      "id": "EznjlYdeJGyY"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Respuesta:\n",
        "print(f\"1. ¬øCu√°ntas rese√±as fueron valoradas con 4?: {tabla_frecuencias[tabla_frecuencias['x_i']==4]['n_i'].values[0]}\")\n",
        "print(f\"2. ¬øCu√°ntas rese√±as fueron valoradas con menos de 3?: {tabla_frecuencias[tabla_frecuencias['x_i']<3]['n_i'].values.sum()}\")\n",
        "print(f\"3. ¬øCu√°ntas rese√±as tienen 4 o menos de valoraci√≥n?: {tabla_frecuencias[tabla_frecuencias['x_i']<5]['n_i'].values.sum()}\")\n",
        "print(f\"4. ¬øCu√°ntas rese√±as tienen m√°s de 4 puntos de valoraci√≥n?: {tabla_frecuencias[tabla_frecuencias['x_i']>4]['n_i'].values.sum()}\")\n",
        "print(f\"5. ¬øCu√°l es la proporci√≥n de rese√±as con puntaje igual a 3?: {round(tabla_frecuencias[tabla_frecuencias['x_i']==3]['f_i'].values.sum(),4)} √≥ {round(tabla_frecuencias[tabla_frecuencias['x_i']==3]['f_i'].values.sum()*100,4)}%\")\n",
        "print(f\"6. ¬øCu√°l es la proporci√≥n de rese√±as menores a 3?: {round(tabla_frecuencias[tabla_frecuencias['x_i']==2]['F_i'].values[0],4)} √≥ {round(tabla_frecuencias[tabla_frecuencias['x_i']==2]['F_i'].values[0]*100,4)}%\")\n",
        "print(f\"7. ¬øCu√°l es la proporci√≥n de rese√±as mayores de 2?: {round(tabla_frecuencias[tabla_frecuencias['x_i']>2]['f_i'].values.sum(),3)} √≥ {round(tabla_frecuencias[tabla_frecuencias['x_i']>2]['f_i'].values.sum()*100,3)}%\")"
      ],
      "metadata": {
        "id": "1BvUhPcuMGnr",
        "cellView": "form"
      },
      "id": "1BvUhPcuMGnr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "416a82f8-198c-4cca-9f8a-5b80c708fdec",
      "metadata": {
        "id": "416a82f8-198c-4cca-9f8a-5b80c708fdec"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "### ALGUNOS TIPOS DE GR√ÅFICOS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para variables **discretas** (toman pocos valores distintos):\n",
        "\n",
        "* Gr√°ficos de sectores: cada valor ocupa un sector circular cuya proporci√≥n de √°rea (con respecto al c√≠rculo que representa el total) es la frecuencia relativa.  \n",
        "* Gr√°ficos de barras. De dos tipos:\n",
        "  * de valores: una barra por cada caso ($ùëÅ$ barras), de manera que la altura de barra ùëñ-√©sima expresa el valor ùëã_ùëñ;\n",
        "  * de frecuencias: una barra por cada valor distinto $ùë•_ùëñ$, de manera que la altura de la barra $ùë•_ùëñ$ expresa su frecuencia absoluta $ùëõ_ùëñ$.\n",
        "\n",
        "Para variables **continuas** (toman un amplio rango de posibles valores):\n",
        "* histogramas.\n",
        "Son gr√°ficos de rect√°ngulos pegados cuyas bases representan los intervalos determinados y cuyas alturas representan sus densidades ($‚Ñé_ùëñ/ùëÅ$).\n",
        "\n",
        "    Se puede considerar que son gr√°ficos de barras de frecuencias especiales.\n",
        "\n",
        "Gr√°ficos para PLN:\n",
        "   * Pol√≠gono de frecuencias.\n",
        "   * Nube de palabras (Word Clouds).\n",
        "   * √Årbol de an√°lisis sint√°ctico\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "d-HCmB6WNIZQ"
      },
      "id": "d-HCmB6WNIZQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58400d04-b18f-4703-aad4-3b4ab3f3f40d",
      "metadata": {
        "id": "58400d04-b18f-4703-aad4-3b4ab3f3f40d",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Gr√°fico de sectores:\n",
        "sizes = tabla_frecuencias.n_i\n",
        "labels = tabla_frecuencias.x_i\n",
        "\n",
        "plt.figure(figsize=(6, 6))  # Tama√±o del gr√°fico (opcional)\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "\n",
        "# Agregar un t√≠tulo\n",
        "plt.title('Gr√°fico de frecuencia del Score')\n",
        "# plt.savefig(\"Pie_chart_score.png\", bbox_inches='tight', pad_inches=0, dpi=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe43711d-93d7-428d-9a83-576d1054db13",
      "metadata": {
        "id": "fe43711d-93d7-428d-9a83-576d1054db13",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Gr√°fico de barras**: Para visualizar un ejemplo, creamos una nueva variable ***Sentiment*** que divide en tres grupos las rese√±as. Las rese√±as con Score de 1, 2 son catalogadas como *Malo*, Score de 3 como *Neutral* y Score de 4 o 5 son catalogadas como *Buenas*.\n",
        "\n",
        "#Primero clasificaremos las rese√±as en doos grupos (buenas o malas)\n",
        "# assign reviews with score > 3 as positive sentiment\n",
        "# score < 3 negative sentiment\n",
        "# score = 3 Neutral\n",
        "df['sentiment'] = pd.cut(df['Score'], bins=[1,3,4,6], labels=['Malo (1-2)', 'Neutral (3)', 'Bueno (4-5)'], right=False)\n",
        "\n",
        "frecuencias_sentiment = df['sentiment'].value_counts()\n",
        "frecuencias_sentiment = frecuencias_sentiment.sort_index()\n",
        "\n",
        "print(f\"Frecuencias por tipo de sentimiento:\\n{frecuencias_sentiment}\")\n",
        "\n",
        "# Datos de ejemplo\n",
        "labels = frecuencias_sentiment.index\n",
        "sizes = frecuencias_sentiment.values\n",
        "\n",
        "# Crear el gr√°fico de barras\n",
        "plt.figure(figsize=(8, 6))  # Tama√±o del gr√°fico (opcional)\n",
        "plt.bar(labels, sizes, color='magenta')\n",
        "\n",
        "# Agregar etiquetas y t√≠tulo\n",
        "plt.ylabel('N¬∫ de rese√±as')\n",
        "plt.xlabel('Sentimiento')\n",
        "# plt.title('Gr√°fico de sentimeinto')\n",
        "# plt.savefig(\"bar_chart_score_agrupado.png\", bbox_inches='tight', pad_inches=0, dpi=600)\n",
        "\n",
        "# Mostrar el gr√°fico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b23b170-fb3e-45bb-993d-baad62311f0f",
      "metadata": {
        "id": "3b23b170-fb3e-45bb-993d-baad62311f0f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Histograma:** Histograma del puntaje de las rese√±as (Score):\n",
        "\n",
        "data=list(df['Score'].values)\n",
        "# Crear el histograma con las barras juntas y densidad\n",
        "plt.figure(figsize=(8, 6))  # Tama√±o del gr√°fico (opcional)\n",
        "values, bins, _ = plt.hist(data, bins=range(min(data), max(data) + 2), align='left', rwidth=1, color='magenta', density=False)\n",
        "\n",
        "# Agregar etiquetas y t√≠tulo\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Densidad')\n",
        "plt.title('Histograma del Score')\n",
        "\n",
        "# Mostrar el histograma\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "#para mostrar las frecuencias reltativas en vez de las aboslutas usar: values, bins, _ = plt.hist(data, bins=range(min(data), max(data) + 2), align='left', rwidth=1, color='magenta', density=False)\n",
        "\n",
        "for i in range(len(values)):\n",
        "    print(f\"Frecuencia del bin {bins[i]} - {bins[i+1]}: {values[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **PLN:** - Pol√≠gono de frecuencias  - Nube de palabras - √Årbol sint√°ntico\n",
        "\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is an interdisciplinary field that combines statistics, mathematics,\n",
        "and machine learning techniques to analyze and understand human language. In NLP, words, tokens,\n",
        "and their frequency play a crucial role in building models for language inference.\n",
        "The foundation of Natural Language Processing lies in understanding the nominal, ordinal,\n",
        "and categorical aspects of language. By employing sophisticated algorithms, NLP systems can decipher\n",
        "the semantics and syntax of words and sentences. In NLP, the power of machine learning models\n",
        "is harnessed to process vast amounts of textual data, enabling tasks such as sentiment analysis,\n",
        "text summarization, and information extraction. Through the application of advanced algorithms,\n",
        "NLP practitioners strive to enhance the accuracy and efficiency of language processing systems.\n",
        "Statistics and mathematics form the backbone of Natural Language Processing, providing the theoretical\n",
        "framework for modeling linguistic phenomena and deriving meaningful insights from textual data.\n",
        "By leveraging statistical techniques, NLP algorithms can identify patterns, trends, and correlations\n",
        "within language corpora. In essence, Natural Language Processing is a multifaceted discipline\n",
        "that draws upon diverse domains such as linguistics, computer science, and artificial intelligence.\n",
        "By exploring the intricate interplay between words, semantics, and context, NLP researchers\n",
        "continue to push the boundaries of language understanding and machine intelligence.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenizar el texto\n",
        "\n",
        "clear_text = limpiar_texto(text,idioma='english')\n",
        "\n",
        "tokens = word_tokenize(clear_text)\n",
        "\n",
        "# Eliminar palabras vac√≠as (stopwords)\n",
        "\n",
        "tokens = [token.lower() for token in tokens if token.isalnum() and token.lower() not in stopword_en]\n",
        "\n",
        "# Calcular la distribuci√≥n de frecuencias\n",
        "freq_dist = FreqDist(tokens)\n",
        "\n",
        "# display(freq_dist)\n",
        "\n",
        "print(\"------------------------------------------------------------\\n Histograma\\n------------------------------------------------------------\\n\")\n",
        "\n",
        "# Histograma de las palabras m√°s comunes\n",
        "freq_dist.plot(30, cumulative=False)\n",
        "\n",
        "print(\"------------------------------------------------------------\\n Nube de palabras\\n------------------------------------------------------------\\n\")\n",
        "\n",
        "# Crear la primera nube de palabras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(tokens))\n",
        "\n",
        "# Crear la segunda nube de palabras con una m√°scara\n",
        "x, y = np.ogrid[:300, :300]\n",
        "mask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2\n",
        "mask = 255 * mask.astype(int)\n",
        "wc = WordCloud(background_color=\"white\", repeat=True, mask=mask)\n",
        "wc.generate(' '.join(tokens))\n",
        "\n",
        "# Crear el gr√°fico con subgr√°ficos\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subgr√°fico 1: Primera nube de palabras\n",
        "axs[0].imshow(wordcloud, interpolation='bilinear')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Nube de Palabras')\n",
        "\n",
        "# Subgr√°fico 2: Segunda nube de palabras con m√°scara\n",
        "axs[1].imshow(wc, interpolation=\"bilinear\")\n",
        "axs[1].axis(\"off\")\n",
        "axs[1].set_title('Nube de Palabras con M√°scara')\n",
        "\n",
        "# Ajustar el dise√±o para evitar solapamientos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar el gr√°fico combinado\n",
        "plt.show()\n",
        "\n",
        "\n",
        "######################\n",
        "\n",
        "print(\"------------------------------------------------------------\\n √Årbol Sint√°ntico\\n------------------------------------------------------------\\n\")\n",
        "\n",
        "# Definimos una oraci√≥n simple en ingl√©s\n",
        "\n",
        "prhase_clear = limpiar_texto(text,\"english\")\n",
        "sentences = sent_tokenize(prhase_clear)\n",
        "\n",
        "# Tokenizar cada oraci√≥n en palabras y eliminar palabras vac√≠as\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "# Etiquetar las palabras con partes del discurso\n",
        "tagged_sentences = [nltk.pos_tag(words) for words in tokenized_sentences]\n",
        "\n",
        "\n",
        "# Crear un diccionario para agrupar las palabras por etiquetas\n",
        "words_by_tag = {}\n",
        "\n",
        "# Iterar sobre las oraciones etiquetadas\n",
        "for tagged_sentence in tagged_sentences:\n",
        "    # Iterar sobre cada palabra etiquetada en la oraci√≥n\n",
        "    for word, tag in tagged_sentence:\n",
        "        # A√±adir la palabra al grupo correspondiente en el diccionario\n",
        "        if tag in words_by_tag:\n",
        "            words_by_tag[tag].append(word)\n",
        "        else:\n",
        "            words_by_tag[tag] = [word]\n",
        "\n",
        "# Crear √°rbol sint√°ctico para cada oraci√≥n\n",
        "print(\"√Årbol sint√°ctico:\")\n",
        "for tagged_sentence in tagged_sentences:\n",
        "    tree = nltk.ne_chunk(tagged_sentence)\n",
        "    print(f\"\\n{tree}\\n\")\n",
        "print(\"Clasificaci√≥n:\")\n",
        "# Imprimir las palabras por grupo de etiquetas\n",
        "for tag, words in words_by_tag.items():\n",
        "    print(f\"Palabras con etiqueta '{tag}':\")\n",
        "    print(\", \".join(words))\n",
        "    print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p1PcXlFjSd6S",
        "cellView": "form"
      },
      "id": "p1PcXlFjSd6S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un **√°rbol sint√°ctico** en PLN proporciona informaci√≥n sobre la estructura gramatical de una oraci√≥n.\n",
        "\n",
        "Al analizar un √°rbol sint√°ctico, se puede obtener:\n",
        "\n",
        "1. Relaciones gramaticales: Permite identificar las relaciones entre las palabras de una oraci√≥n, como sujeto, verbo, objeto, complementos, etc.\n",
        "\n",
        "2. Desambiguaci√≥n: Ayuda a desambiguar frases complejas al mostrar claramente la estructura y las relaciones entre las palabras\n",
        "\n",
        "3. An√°lisis de dependencias: Permite comprender la relaci√≥n entre las palabras y c√≥mo interact√∫an para formar frases significativas\n",
        "\n",
        "4. Extracci√≥n de informaci√≥n: Facilita la extracci√≥n de informaci√≥n relevante para tareas como res√∫menes de texto, an√°lisis de sentimientos y traducci√≥n autom√°tica\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/abreviaciones.png?raw=1\" alt=\"abrevaciones\" width=\"70%\" height=\"70%\">  \n",
        "</center>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s44b5_tQv6FE"
      },
      "id": "s44b5_tQv6FE"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prueba b√°sica en espa√±ol:\n",
        "\n",
        "phrase = \"Estoy aprendiendo PLN en Python y quisiera probar c√≥mo funciona un √°rbol sint√°ctico en Espa√±ol\"\n",
        "prhase_clear = limpiar_texto(phrase,\"spanish\")\n",
        "\n",
        "doc = nlp(prhase_clear)\n",
        "# Obtener etiquetas de partes del discurso\n",
        "tagged_sentences = [(token.text, token.pos_) for token in doc]\n",
        "\n",
        "# Crear √°rbol sint√°ctico para cada oraci√≥n\n",
        "for tagged_sentence in tagged_sentences:\n",
        "    tree = nltk.ne_chunk(tagged_sentence)\n",
        "    print(f\"\\n{tree}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7vmxsK964otq"
      },
      "id": "7vmxsK964otq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "615df32b-c6ff-4201-a8a9-dc76376069c7",
      "metadata": {
        "id": "615df32b-c6ff-4201-a8a9-dc76376069c7"
      },
      "source": [
        "***\n",
        "## Medidas de posici√≥n: media, mediana, cuantiles y moda.\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para hacer manejable la masa de datos procedentes de la observaci√≥n estad√≠stica, es necesario resumir el volumen de los datos. Ya hemos visto c√≥mo reducir y organizar la masa de datos con las tablas de frecuencias.\n",
        "\n",
        "En el caso de las **variables cuantitativas**, es posible reducir a√∫n m√°s esta informaci√≥n, vali√©ndonos de unos pocos valores que las describan y caractericen. Estos valores, que llamamos estad√≠sticos, nos indican las caracter√≠sticas m√°s importantes de las distribuciones de frecuencias y se suelen clasificar en los siguientes grupos:\n",
        "\n",
        "* de posici√≥n:\n",
        "    * media aritm√©tica\n",
        "    * mediana\n",
        "    * cuantiles\n",
        "    * moda\n",
        "* de dispersi√≥n:\n",
        "    * varianza\n",
        "    * desviaci√≥n t√≠pica\n"
      ],
      "metadata": {
        "id": "YliNLDWXPIY4"
      },
      "id": "YliNLDWXPIY4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medidas de posici√≥n:\n",
        "\n",
        "Las **medidas de posici√≥n** resumen la distribuci√≥n de los valores de una variable.\n",
        "\n",
        "Para que un valor pueda ser considerado una medida de posici√≥n tiene que tomar un valor **comprendido entre el m√≠nimo y el m√°ximo de la variable.**\n",
        "\n",
        "Existen dos tipos de medidas de posici√≥n: las **centrales** y las **no centrales**.\n",
        "\n",
        "De las medidas de posici√≥n central, las m√°s utilizadas son: la **media aritm√©tica**, la **mediana** y la **moda**.\n",
        "\n",
        "Los **cuantiles** son las medidas de posici√≥n no central.\n"
      ],
      "metadata": {
        "id": "epOYDGEGPprx"
      },
      "id": "epOYDGEGPprx"
    },
    {
      "cell_type": "markdown",
      "id": "e739def1-b32a-40d8-b998-6666c56cc3e7",
      "metadata": {
        "id": "e739def1-b32a-40d8-b998-6666c56cc3e7"
      },
      "source": [
        "***\n",
        "### Media Aritm√©tica\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La media aritm√©tica es la suma de todos los valores observados de la distribuci√≥n, dividida por el n√∫mero total de casos.\n",
        "$$\\bar{X}=\\frac{1}{N} \\sum_{(ùëñ=1)}^{ùëÅ}ùëã_{ùëñ} =\\frac{(ùëã_1+ùëã_2+‚Ä¶+ùëã_ùëÅ)}{N}.$$\n",
        "\n",
        "Si tenemos $ùêæ$ valores distintos que se repiten, y conocemos sus frecuencias, podemos calcular la media como:\n",
        "$$\\bar{X}=\\frac{1}{N} \\sum_{(ùëñ=1)}^{ùëÅ}n_{ùëñ}ùë•_{ùëñ} =\\frac{(ùëõ_1 ùë•_1+ùëõ_2 ùë•_2+‚Ä¶+ùëõ_ùëò ùë•_ùêæ)}{N}.$$"
      ],
      "metadata": {
        "id": "SQJSt7rsPzlA"
      },
      "id": "SQJSt7rsPzlA"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Genera suma de $X_i$ y valor de N para la variable *Longitud_texto*\n",
        "print(f\"La suma de X_i para el ejercicio es {df['Longitud_Texto'].sum()}\" )\n",
        "print(f\"El tama√±o (N) de X_i para el ejercicio es {N}\")"
      ],
      "metadata": {
        "id": "PI3Ny-GSD--n",
        "cellView": "form"
      },
      "id": "PI3Ny-GSD--n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicios:\n",
        "\n",
        "Calcular la media aritm√©tica en las siguientes situaciones.\n",
        "\n",
        "1. Para la variable $X=(4, 7, 5, 7, 5, 4, 2, 7)$.\n",
        "\n",
        "2. Para la variable **Longitud_Texto**:\n",
        "\n",
        "    Sabiendo que $\\sum ùëã_{ùëñ}=3638051$   y $N= 45476$\n",
        "\n",
        "3. Usando la reducci√≥n por intervalos de la tabla de frecuencias de la variable **Longitud_Texto** (C√°lculo de la marca de clase)\n"
      ],
      "metadata": {
        "id": "Zor5i4_2Q9AL"
      },
      "id": "Zor5i4_2Q9AL"
    },
    {
      "cell_type": "markdown",
      "id": "6ce1a628-cffc-4ec0-9354-9547312f99dd",
      "metadata": {
        "id": "6ce1a628-cffc-4ec0-9354-9547312f99dd"
      },
      "source": [
        "### Media aritm√©tica de datos agrupados:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Respuestas** 1 y 2 { display-mode: \"code\" }\n",
        "X = [4, 7, 5, 7, 5, 4, 2, 7]\n",
        "x_hat = round(sum(X) / len(X),2)\n",
        "# Imprimir el texto junto con la variable y su valor\n",
        "print(f\"1. Para la variable X = {X}: \\u0302x={x_hat}\")\n",
        "\n",
        "# Para la variable Longitud_Texto:\n",
        "x_hat = round(df[\"Longitud_Texto\"].mean(),2)\n",
        "suma = df[\"Longitud_Texto\"].sum()\n",
        "n = N\n",
        "print(f\"2. Para la variable Longitud_Texto: \\u0302x={suma}/{n}={x_hat}\")"
      ],
      "metadata": {
        "id": "JL5OERi2Xt9g"
      },
      "id": "JL5OERi2Xt9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0fca20-df91-4177-b6a0-96ecd37ed692",
      "metadata": {
        "id": "ce0fca20-df91-4177-b6a0-96ecd37ed692",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Crea marca de clase:\n",
        "# Mostrar la tabla de frecuencias con la marca de clase\n",
        "print(tabla_frecuencias_Longitud_Texto[['x_i','MarcaDeClase','n_i']])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Rta 3.\n",
        "marcas_de_clase =  tabla_frecuencias_Longitud_Texto['MarcaDeClase']\n",
        "frecuencias     =  tabla_frecuencias_Longitud_Texto['n_i']\n",
        "# Calculando la suma de los productos de las marcas de clase y las frecuencias\n",
        "suma_productos = sum(marcas_de_clase[i] * frecuencias[i] for i in range(len(marcas_de_clase)))\n",
        "\n",
        "# # Calculando el total de observaciones\n",
        "total_observaciones = sum(frecuencias)\n",
        "\n",
        "# # Calculando la media aritm√©tica\n",
        "x_hat = suma_productos / total_observaciones\n",
        "\n",
        "print(f\"3. Para la variable Longitud_Texto en datos agrupados:\\n\\u0302x={round(x_hat,2)}\")"
      ],
      "metadata": {
        "id": "EdZzerA7FfmC",
        "cellView": "form"
      },
      "id": "EdZzerA7FfmC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Media aritm√©tica: pros\n",
        "\n"
      ],
      "metadata": {
        "id": "uWp8GFJ9wGV2"
      },
      "id": "uWp8GFJ9wGV2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiene en cuenta **todos los valores observados**.\n",
        "\n",
        "Es **f√°cil de calcular.**\n",
        "\n",
        "Tiene un **claro significado estad√≠stico:** representa el valor que tomar√≠a cada una de las observaciones si el total se repartiera de manera equitativa.\n",
        "\n",
        "Es **√∫nica**."
      ],
      "metadata": {
        "id": "LobQIalqwiSs"
      },
      "id": "LobQIalqwiSs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Media aritm√©tica: contras"
      ],
      "metadata": {
        "id": "UUtkoVfFwcQC"
      },
      "id": "UUtkoVfFwcQC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los valores extremos ejercen gran influencia sobre el valor de la media aritm√©tica (un valor extremo es un dato excepcionalmente peque√±o o grande en comparaci√≥n con el resto)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FN7Q9wipwkR4"
      },
      "id": "FN7Q9wipwkR4"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ejemplo:\n",
        "Datos1 = [2,5,7,9,12]\n",
        "Datos2 = [2,5,7,9,125]\n",
        "Datos = pd.DataFrame({\n",
        "    'Datos1': Datos1,\n",
        "    'Datos2': Datos2\n",
        "})\n",
        "display(Datos)"
      ],
      "metadata": {
        "id": "YtVMcdY8xoBp",
        "cellView": "form"
      },
      "id": "YtVMcdY8xoBp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcula la media de los dos conjuntos de datos:\n",
        "# Calcular las medias de Datos1 y Datos2\n",
        "media_datos1 = sum(Datos1) / len(Datos1)\n",
        "media_datos2 = sum(Datos2) / len(Datos2)\n",
        "\n",
        "# Crear la figura y los subgr√°ficos\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Gr√°fico de barras para Datos1\n",
        "axs[0].bar(range(len(Datos1)), Datos1, color='skyblue')\n",
        "axs[0].axhline(y=media_datos1, color='skyblue', linestyle='--', label=f'Media: {media_datos1}')\n",
        "axs[0].set_title('Datos1')\n",
        "axs[0].set_xticks(range(len(Datos1)))\n",
        "axs[0].set_xticklabels(range(1, len(Datos1) + 1))\n",
        "axs[0].legend()\n",
        "\n",
        "# Gr√°fico de barras para Datos2\n",
        "axs[1].bar(range(len(Datos2)), Datos2, color='salmon')\n",
        "axs[1].axhline(y=media_datos2, color='salmon', linestyle='--', label=f'Media: {media_datos2}')\n",
        "axs[1].set_title('Datos2')\n",
        "axs[1].set_xticks(range(len(Datos2)))\n",
        "axs[1].set_xticklabels(range(1, len(Datos2) + 1))\n",
        "axs[1].legend()\n",
        "\n",
        "# Ajustar el espaciado entre los subgr√°ficos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar el gr√°fico\n",
        "plt.show()\n",
        "print(f'La media de los Datos 1 es {media_datos1}\\n\\nLa media de los Datos 2 es {media_datos2}')"
      ],
      "metadata": {
        "id": "OOIymyBcYA_W",
        "cellView": "form"
      },
      "id": "OOIymyBcYA_W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Media aritm√©tica: propiedades\n",
        "\n",
        "\n",
        "* La suma de las desviaciones de los valores de la variable, respecto a su media aritm√©tica, es igual a cero:\n",
        "$$\\sum(X_{i}‚àí\\bar{X})= 0 $$.\n",
        "\n",
        "* Si transformamos los valores de la variable  a trav√©s de un cambio de origen y escala $(U=a+bX)$, la media aritm√©tica de la variable transformada es $\\bar{U}= a+b\\bar{X}$.\n",
        "\n",
        "* En particular (para $b=1$) si $U=a+X$ entonces $\\bar{U}= a+\\bar{X}$.\n",
        "\n",
        "    * Ejemplo. Supongamos que tenemos el peso de $N = 20$ personas $X = (59, 41, 55, 79, 61, 83, 43, 54, 89, 57, 80, 86, 67, 56, 80, 42, 60, 83, 76, 87)$.\n",
        "\n",
        "    * Ahora, supongamos que hacemos la tranformaci√≥n $\\bar{U}= a+\\bar{X}$ d√≥nde $a=10$ y $b=1$, entonces $U = (69, 51, 65, 89, 71, 93, 53, 64, 99, 67, 90, 96, 77, 66, 90, 52, 70, 93, 86, 9)$\n",
        "\n",
        "    * Entonces $\\bar{U}= a+\\bar{X} = 10 + \\frac{\\sum_{i}{X}}{20} ‚â° \\frac{\\sum_{i}U}{20}$\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "lc32TP7c1cli"
      },
      "id": "lc32TP7c1cli"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Genera listas X y U y calcula las medias:\n",
        "# Generar la lista X\n",
        "# X = [random.randint(40, 90) for _ in range(20)]\n",
        "X = [59, 41, 55, 79, 61, 83, 43, 54, 89, 57, 80, 86, 67, 56, 80, 42, 60, 83, 76, 87]\n",
        "\n",
        "print(f\"Lista X: {X}\\ny la suma de X: {sum(X)}\")\n",
        "a = 10\n",
        "b = 1\n",
        "\n",
        "# Generar la lista U.\n",
        "U = [b*x + a for x in X]\n",
        "print(f\"Lista U: {U}\\ny la suma de U: {sum(U)}\")\n",
        "\n",
        "x_bar= sum([i for i in X]) / len([i for i in X])\n",
        "print(\"utilizando la conversi√≥n:\\n\")\n",
        "print(f\"La media de U = {b} X {x_bar} + {a}= {round(b*x_bar+a,1)}\")\n",
        "print(\"Calculando  la  media de U directamente:\\n\")\n",
        "print(f\"La media de U =  {sum([i for i in U]) / len([i for i in U])}\")"
      ],
      "metadata": {
        "id": "poiWABWkyTO3",
        "cellView": "form"
      },
      "id": "poiWABWkyTO3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Si dividimos todas las observaciones en $k$ grupos disjuntos, cada uno de ellos con media $\\bar{x}_{i}$ y tama√±o $ùëÅ_{ùëñ}$, la media aritm√©tica de todo el conjunto se puede calcular como\n",
        "$$\\bar{X}=\\frac{(\\bar{X}_{1}N_{1}+‚Ä¶+\\bar{X}_{k}N_{k})}{N}$$"
      ],
      "metadata": {
        "id": "9aX7TBiu5mdP"
      },
      "id": "9aX7TBiu5mdP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## Mediana\n",
        "***\n",
        "\n",
        "Dada una variable $X$, su mediana, $Me(X)$, es el valor tal que es mayor que la mitad (al menos) de los casos y tambi√©n es menor o igual que (al menos) la mitad de los casos.\n",
        "\n",
        "Para calcular la mediana buscamos el valor central en la lista de valores ordenados de $X$. Para ello, ordenamos los casos de manera que $X_{1} < X_{2} < ... < X_{N} $. Calculamos la posici√≥n central $\\frac{(N+1)}{2}$:\n",
        "\n",
        "* Si el resultado es entero (esto es, si $N$ es impar), entonces $Me(X)=X_{(N+1)/2}$.\n",
        "\n",
        "* En otro caso (si $N$ es par): $Me(X)=\\frac{(X_{(N)/2}+X_{(N+2)/2})}{2}$, esto es, el promedio de los valores en las posiciones inmediatamente anterior y posterior a $\\frac{(N+1)}{2}$.\n",
        "\n",
        "¬ø$X$ est√° reducida por intervalos? $\\rightarrow$ Lo veremos m√°s adelante.\n"
      ],
      "metadata": {
        "id": "o-ejPKQKyyZB"
      },
      "id": "o-ejPKQKyyZB"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcula la mediana:\n",
        "# Ejemplo de datos\n",
        "datos = df['Longitud_Texto']\n",
        "\n",
        "# Calcular la mediana\n",
        "mediana = calcular_mediana(datos)\n",
        "\n",
        "# Imprimir la mediana\n",
        "print(\"La mediana de la longitud de palabras de las rese√±as es:\", mediana)\n"
      ],
      "metadata": {
        "id": "afpRMY1Kyzzy",
        "cellView": "form"
      },
      "id": "afpRMY1Kyzzy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra forma de hacerlo (funci√≥n predise√±ada):"
      ],
      "metadata": {
        "id": "pGHRDcNSHDFg"
      },
      "id": "pGHRDcNSHDFg"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title C√°lculo de la mediana con funci√≥n de Python:\n",
        "#Se requiere el uso de la funci√≥n median de la librer√≠a statistics:\n",
        "# Calcular la mediana\n",
        "mediana2 = median(datos)\n",
        "\n",
        "# Imprimir la mediana\n",
        "print(\"La mediana de los datos es:\", mediana2)"
      ],
      "metadata": {
        "id": "DH2gbJhNFF-Z",
        "cellView": "form"
      },
      "id": "DH2gbJhNFF-Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mediana por intervalos:\n",
        "\n",
        "Si la variable $X$ est√° reducida por intervalos, tomaremos como $Me(X)$ la marca de clase del **intervalo mediano**.\n",
        "\n",
        "El intervalo mediano es el primer intervalo cuya frecuencia absoluta acumulada sea mayor o igual a $(N+1)/2$. De manera equivalente, tambi√©n podemos obtenerlo buscando el primer intervalo tal que su frecuencia absoluta relativa sea mayor o igual a $\\frac{1}{2}=0.5$. Esto es, el intervalo mediano es el intervalo $i$ tal que:\n",
        "$$N_{i} \\geq \\frac{N+1}{2}$$ y $$N_{i-1} < \\frac{N+1}{2}$$\n",
        "\n",
        "O de manera equivalente, $F_{i} \\geq 0.5$ y $F_{i-1} < 0.5$.\n"
      ],
      "metadata": {
        "id": "gRYpfIh4HY1i"
      },
      "id": "gRYpfIh4HY1i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "C√≥mo ejemplo, utilizaremos un nuevo texto que contiene 218 palabras (119 luego de la limpieza):\n",
        "\n",
        "***\n",
        "***Este texto que est√°s leyendo ahora mismo sirve como un ejemplo ilustrativo para calcular el n√∫mero mediano de la longitud de palabras dentro de un texto determinado. Es un ejercicio pr√°ctico que nos permite comprender c√≥mo funcionan los c√°lculos de estad√≠sticas descriptivas aplicadas al an√°lisis ling√º√≠stico.\n",
        "En este contexto, la longitud de las palabras se refiere al n√∫mero de caracteres que componen cada palabra individualmente. Al analizar este texto, encontrar√°s palabras cortas, como \"este\", \"es\", \"un\", \"de\", as√≠ como palabras m√°s largas como \"ilustrativo\", \"estad√≠sticas\", \"descriptivas\", entre otras.\n",
        "El objetivo es determinar el n√∫mero mediano de caracteres que conforman las palabras en este texto. Al calcular este valor, podemos tener una idea m√°s clara de la extensi√≥n promedio de las palabras utilizadas aqu√≠. Este proceso implica ordenar las longitudes de las palabras de menor a mayor y encontrar el valor medio.\n",
        "Este ejercicio es √∫til en diversos contextos, desde an√°lisis de texto en ling√º√≠stica computacional hasta la elaboraci√≥n de informes y an√°lisis de contenido en campos como la investigaci√≥n acad√©mica, la publicidad y el procesamiento del lenguaje natural.\n",
        "Es importante destacar que el c√°lculo del n√∫mero mediano de longitud de palabras nos brinda informaci√≥n valiosa sobre la estructura y complejidad del lenguaje utilizado, lo que puede tener implicaciones significativas en la comunicaci√≥n efectiva y la comprensi√≥n del texto.***\n",
        "***\n",
        "\n",
        "\n",
        "Al que calcularemos la mediana de la longitud de las palabras dentro del texto, teniendo la tabla de frecuencias agrupadas por ***intervalos***:\n"
      ],
      "metadata": {
        "id": "9pMQAv1hJT8f"
      },
      "id": "9pMQAv1hJT8f"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ejercicio: C√°lculo de mediana en datos agrupados por intervalos:\n",
        "\n",
        "texto = \"\"\"\n",
        "Este texto que est√°s leyendo ahora mismo sirve como un ejemplo ilustrativo para calcular el n√∫mero mediano de la longitud de palabras dentro de un texto determinado. Es un ejercicio pr√°ctico que nos permite comprender c√≥mo funcionan los c√°lculos de estad√≠sticas descriptivas aplicadas al an√°lisis ling√º√≠stico.\n",
        "\n",
        "En este contexto, la longitud de las palabras se refiere al n√∫mero de caracteres que componen cada palabra individualmente. Al analizar este texto, encontrar√°s palabras cortas, como \"este\", \"es\", \"un\", \"de\", as√≠ como palabras m√°s largas como \"ilustrativo\", \"estad√≠sticas\", \"descriptivas\", entre otras.\n",
        "\n",
        "El objetivo es determinar el n√∫mero mediano de caracteres que conforman las palabras en este texto. Al calcular este valor, podemos tener una idea m√°s clara de la extensi√≥n promedio de las palabras utilizadas aqu√≠. Este proceso implica ordenar las longitudes de las palabras de menor a mayor y encontrar el valor medio.\n",
        "\n",
        "Este ejercicio es √∫til en diversos contextos, desde an√°lisis de texto en ling√º√≠stica computacional hasta la elaboraci√≥n de informes y an√°lisis de contenido en campos como la investigaci√≥n acad√©mica, la publicidad y el procesamiento del lenguaje natural.\n",
        "\n",
        "Es importante destacar que el c√°lculo del n√∫mero mediano de longitud de palabras nos brinda informaci√≥n valiosa sobre la estructura y complejidad del lenguaje utilizado, lo que puede tener implicaciones significativas en la comunicaci√≥n efectiva y la comprensi√≥n del texto.\n",
        "\"\"\"\n",
        "\n",
        "# Limpiar el texto original\n",
        "texto_limpio = limpiar_texto(texto, \"spanish\")\n",
        "\n",
        "print(\"---------\")\n",
        "print(f\"\\nTexto:\\n{texto_limpio}\\n\")\n",
        "palabras = texto_limpio.split()\n",
        "\n",
        "longitudes = [len(palabra) for palabra in palabras]\n",
        "\n",
        "pal_long= pd.DataFrame({\n",
        "    'palabras': palabras,\n",
        "    'longitudes': longitudes})\n",
        "pal_long['longitudes_group'] = group_by_sturges(pal_long, 'longitudes')\n",
        "\n",
        "N_ej3=pal_long.shape[0]\n",
        "print(f\"Tama√±o del conjunto de datos: {N_ej3} palabras\")\n",
        "display(pal_long)\n",
        "\n",
        "# Calcular la tabla de frecuencias de la columna 'Grupo'\n",
        "frecuencias_grupo_ej3 = pal_long['longitudes_group'].value_counts()\n",
        "frecuencias_grupo_ej3 = frecuencias_grupo_ej3.sort_index()\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "frecuencias_relativas_gr_ej3 = frecuencias_grupo_ej3 / len(pal_long)\n",
        "\n",
        "# Calcular las frecuencias acumuladas\n",
        "frecuencias_acumuladas_gr_ej3 = frecuencias_grupo_ej3.cumsum()\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "frecuencias_relativas_acum_gr_ej3 = frecuencias_acumuladas_gr_ej3 / len(pal_long)\n",
        "\n",
        "\n",
        "# Calcular la marca de clase para cada intervalo\n",
        "MarcaDeClase_ej3 = list(map(marca_de_clase, list(frecuencias_grupo_ej3.index)))\n",
        "\n",
        "# Crear DataFrame con las frecuencias\n",
        "tabla_frecuencias_eje3 = pd.DataFrame({\n",
        "    'x_i': frecuencias_grupo_ej3.index,\n",
        "    'n_i': frecuencias_grupo_ej3.values,\n",
        "    'f_i': frecuencias_relativas_gr_ej3.values,\n",
        "    'N_i':frecuencias_acumuladas_gr_ej3.values,\n",
        "    'F_i':frecuencias_relativas_acum_gr_ej3.values,\n",
        "    'Marca_de_clase':MarcaDeClase_ej3\n",
        "})\n",
        "\n",
        "# Imprimir la tabla de frecuencias\n",
        "print(\"Tabla de frecuencias:\")\n",
        "print(\"-----------------------------------------------------------------------------------------------------------\")\n",
        "print(\"Longitud   | Frecuencia   | Frecuencia Relativa | Frec. Abs. Acumulada | Frec. Rel. Acumulada | Marca de clase\")\n",
        "print(\"-----------------------------------------------------------------------------------------------------------\")\n",
        "for indice, fila in tabla_frecuencias_eje3.iterrows():\n",
        "    # print(f'√çndice: {indice}')\n",
        "    # print(f'Contenido de la fila:\\n{fila}\\n')\n",
        "\n",
        "    print(f\"{fila[0]:^9}    | {fila[1]:^10}| {fila[2]:.4f}              | {fila[3]:^19}  | {fila[4]:.4f}              | {fila[5]:.1f}\")\n",
        "print(\"-----------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FKzf9KwjGuo_",
        "cellView": "form"
      },
      "id": "FKzf9KwjGuo_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Soluci√≥n del ejercicio: { vertical-output: true }\n",
        "pto = (N_ej3+1)/2\n",
        "print(f\"Intervalo mediano: {pto}\")\n",
        "\n",
        "mediana=round(tabla_frecuencias_eje3.loc[(tabla_frecuencias_eje3['N_i'] >= pto).idxmax(),\"Marca_de_clase\"])\n",
        "print(f\"La mediana de longitud de palabras del texto de prueba es: {mediana}\")\n",
        "\n",
        "# median(longitudes)#para corroborar los datos se puede calcular la mediana de los datos sin agrupar en intervalos\n",
        "\n"
      ],
      "metadata": {
        "id": "xYgoQc1sy2-M",
        "cellView": "form"
      },
      "id": "xYgoQc1sy2-M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mediana pros y contras:\n",
        "\n",
        "### Pros:\n",
        "\n",
        "- **Robustez ante valores extremos:** La mediana no es sensible a los valores extremos o at√≠picos en los datos. Esto significa que un valor extremo no afecta significativamente la mediana, lo que la hace √∫til cuando los datos contienen valores at√≠picos que, c√≥mo dijimos antes, podr√≠an distorsionar la media.\n",
        "   \n",
        "- **Apropiada para datos ordinales o intervalos:** La mediana es √∫til cuando se trabaja con datos ordinales o de intervalos, donde el orden de los valores es importante, pero no necesariamente su magnitud exacta.\n",
        "\n",
        "- **Interpretaci√≥n sencilla:** Es f√°cil de entender y calcular. Consiste en el valor que divide a la muestra ordenada en dos partes iguales, de modo que la mitad de los valores est√°n por encima y la otra mitad por debajo.\n",
        "\n",
        "### Contras:\n",
        "\n",
        "- **Menos sensible a la distribuci√≥n de los datos:** La mediana no utiliza toda la informaci√≥n en los datos y, por lo tanto, puede ser menos sensible que la media para detectar patrones o cambios en la distribuci√≥n de los datos.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z3qeuzT7G1Ji"
      },
      "id": "Z3qeuzT7G1Ji"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Ejercicio** ¬øCu√°l es la mediana en cada caso?\n",
        "display(Datos)"
      ],
      "metadata": {
        "id": "h4xIQpQxF0yH",
        "cellView": "form"
      },
      "id": "h4xIQpQxF0yH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## Moda:\n",
        "***\n",
        "\n",
        "La moda es (son) el (los) valor(es) de frecuencia m√°xima. Puede haber m√°s de una moda. La denotamos como $Mo(X)$.\n",
        "\n",
        "Ejemplo. Para la variable $X =(4, 7, 5, 7, 5, 4, 2, 7)$, tenemos $Mo(X)=7$, que es el valor con mayor frecuencia absoluta.\n",
        "\n",
        "Se suele considerar una medida de posici√≥n central, pero no tiene porqu√© comportarse como tal. Por ejemplo:\n",
        "En el ejemplo anterior $Mo(X)= max(X)$.\n",
        "Para la variable $X=(4, 7, 4, 7, 5, 4, 5, 7)$, tenemos $Mo(X)={4,7}$, que son los valores m√≠nimo y m√°ximo de X.\n",
        "\n",
        "Si nos dan $X$ reducida por intervalos, todo aquel intervalo con densidad de frecuencia m√°xima es intervalo modal (aquellos con altura m√°xima en el histograma). Reportaremos la moda como la(s) marca(s) de clase de el (los) intervalo(s) modal(es) como $Mo(X)$.\n",
        "\n",
        "***Ejemplo:*** Continuando con el ejemplo anterior, del texto que hemos generado, calcularemos la moda de los datos, tanto sin agrupar, como agrupados:"
      ],
      "metadata": {
        "id": "Us59_GftJ3zm"
      },
      "id": "Us59_GftJ3zm"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Longitudes sin agrupar en intervalos: ¬øCu√°l es la moda?\n",
        "# Calcular la tabla de frecuencias de la columna 'Grupo'\n",
        "freq_longitudes = pal_long['longitudes'].value_counts()\n",
        "freq_longitudes = freq_longitudes.sort_index()\n",
        "print(freq_longitudes)\n",
        "pal_long['longitudes'].hist()"
      ],
      "metadata": {
        "id": "T0vpdY0RLiQ4",
        "cellView": "form"
      },
      "id": "T0vpdY0RLiQ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Longitudes agrupadas por intervalos: ¬øCu√°l es la moda?\n",
        "tabla_frecuencias_eje3"
      ],
      "metadata": {
        "id": "jA1iU5KXNNzs",
        "cellView": "form"
      },
      "id": "jA1iU5KXNNzs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moda pros y contras:\n",
        "\n",
        "### Pros:\n",
        "- Es muy f√°cil de calcular, sobre todo para variables descritas por las frecuencias de sus valores, ya que consiste en identificar el (los) valor(es) con frecuencia m√°xima. Si la variable est√° reducida por intervalos de igual amplitud, podremos obtener la moda de esta manera.\n",
        "\n",
        "### Contras:\n",
        "- Realmente no es una medida de posici√≥n central. Sin embargo, para variables unimodales y con cierta simetr√≠a (esta caracter√≠stica se puede apreciar en el gr√°fico de barras de frecuencias o en el histograma), s√≠ que representa una centralidad.\n",
        "- Cuando los valores de la variable no se repiten, no tiene sentido (no nos da ninguna informaci√≥n) ya que todos los valores son modas.\n",
        "Ejemplo: para la distribuci√≥n $X=(2, 5, 7, 9, 12)$ todos los valores son moda.\n"
      ],
      "metadata": {
        "id": "IHosDESvNtH-"
      },
      "id": "IHosDESvNtH-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## Cuantiles:\n",
        "***\n",
        "\n",
        "Las ***medidas de posici√≥n no central*** m√°s conocidas son los cuantiles, que podemos ver como una generalizaci√≥n de la mediana:\n",
        "\n",
        "La *mediana* es el cuantil de orden 2: separa los valores ordenados en dos bloques iguales en n√∫mero de casos.\n",
        "\n",
        "Los cuartiles $Q_{1}$, $Q_{2}$ y $Q_{3}$son los cuantiles de orden 4: separan los valores ordenados en cuatro bloques iguales en n√∫mero de casos.\n",
        "\n",
        "Los percentiles $P_{1}$, $P_{2}$, ..., $P_{99}$ son los de orden 100, y separan los valores ordenados en 100 bloques iguales en n√∫mero de casos.\n",
        "\n",
        "Los deciles $D_{1}$, $D_{2}$, ..., $D_{9}$ son los de orden 10.\n",
        "\n",
        "Otros cuantiles menos habituales: los terciles (orden 3), los quintiles (orden 5) ‚Ä¶\n"
      ],
      "metadata": {
        "id": "yVfrMANlOyGp"
      },
      "id": "yVfrMANlOyGp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¬øC√≥mo se calculan?:\n",
        "\n",
        "Ordenamos los datos: $X_{1} \\leq X_{1} \\leq ... \\leq X_{N}$.\n",
        "\n",
        "Para el orden $q$ se definen $q-1$ cuantiles de n√∫mero $r=1, 2, ..., q-1$.\n",
        "\n",
        "El ùëü-√©simo cuantil de orden $q$ es el valor que ocupa la posici√≥n $\\frac{r}{q}(N+1)$:\n",
        "- si el resultado de la posici√≥n es entero, reportamos el valor de esa posici√≥n, $X_{i}$ tal que $$i=\\frac{r}{q}(N+1)$$\n",
        "- en otro caso, reportamos la media aritm√©tica de los valores que ocupan las posiciones inmediatamente anterior y posterior a la posici√≥n obtenida, esto es, $$\\frac{X_{i}+X_{i+1}}{2}$$\n",
        "tal que $i < \\frac{r}{q}(N+1) < i+1$.\n",
        "\n",
        "**Observaci√≥n**. Muchos cuantiles de distintos ordenes coinciden, por ejemplo:\n",
        "$Q_{1} = P_{2}$ (la cuarta parte es el 25%);\n",
        "\n",
        "$Q_{2} = Me = P_{50}$ (2/4=1/2=50/100);\n",
        "\n",
        "$Q_{3} = P_{75}$ (3/4=75/100).\n"
      ],
      "metadata": {
        "id": "_k_ZskrNWFHP"
      },
      "id": "_k_ZskrNWFHP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cuantiles: Ejercicio:\n",
        "Calcular los cuantiles\n",
        "\n",
        "El objetivo de este ejercicio es calcular los diferentes cuantiles de la longitud de las palabras del texto:\n",
        "\n",
        "***Texto:***\n",
        "***\n",
        "***Este texto que est√°s leyendo ahora mismo sirve como un ejemplo ilustrativo para calcular el n√∫mero mediano de la longitud de palabras dentro de un texto determinado. Es un ejercicio pr√°ctico que nos permite comprender c√≥mo funcionan los c√°lculos de estad√≠sticas descriptivas aplicadas al an√°lisis ling√º√≠stico.\n",
        "En este contexto, la longitud de las palabras se refiere al n√∫mero de caracteres que componen cada palabra individualmente. Al analizar este texto, encontrar√°s palabras cortas, como \"este\", \"es\", \"un\", \"de\", as√≠ como palabras m√°s largas como \"ilustrativo\", \"estad√≠sticas\", \"descriptivas\", entre otras.\n",
        "El objetivo es determinar el n√∫mero mediano de caracteres que conforman las palabras en este texto. Al calcular este valor, podemos tener una idea m√°s clara de la extensi√≥n promedio de las palabras utilizadas aqu√≠. Este proceso implica ordenar las longitudes de las palabras de menor a mayor y encontrar el valor medio.\n",
        "Este ejercicio es √∫til en diversos contextos, desde an√°lisis de texto en ling√º√≠stica computacional hasta la elaboraci√≥n de informes y an√°lisis de contenido en campos como la investigaci√≥n acad√©mica, la publicidad y el procesamiento del lenguaje natural.\n",
        "Es importante destacar que el c√°lculo del n√∫mero mediano de longitud de palabras nos brinda informaci√≥n valiosa sobre la estructura y complejidad del lenguaje utilizado, lo que puede tener implicaciones significativas en la comunicaci√≥n efectiva y la comprensi√≥n del texto.***\n",
        "***\n",
        "\n",
        "\n",
        "Recordemos que en el ejercicio anterior limpiamos el texto, por lo que utilizaremos la variable creada **texto_limpio**.\n",
        "Calcularemos los valores que dividen la distribuci√≥n de la longitud de las palabras, primero en 4 partes iguales, es decir los cuartiles, y luego en 10 partes iguales, es decir, los deciles."
      ],
      "metadata": {
        "id": "ea1TWQLxebil"
      },
      "id": "ea1TWQLxebil"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title C√°lculo de los cuartiles y deciles de la longitud de palabras del texto de ejemplo:\n",
        "try:\n",
        "    pal_long = pal_long.sort_values(by=\"longitudes\").reset_index()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "display(pal_long[['longitudes']])\n",
        "N_1=N_ej3+1\n",
        "print(\"------------------------------------------------------------\\n------------------------------------------------------------\\n\")\n",
        "\n",
        "#por ejemplo los cuartiles:\n",
        "q=4 #entonces q-1 grupos\n",
        "print(\"------------------------------------------------------------\\nPara los cuartiles\\n------------------------------------------------------------\\n\")\n",
        "for r in range(1,q):\n",
        "    i=(r/q)*N_1\n",
        "\n",
        "    if i.is_integer():\n",
        "        cuant =  pal_long.loc[int(i)-1,'longitudes']\n",
        "    else:\n",
        "        # lower_index = int(i) - 1\n",
        "        # upper_index = int(i)\n",
        "        # cuant = (pal_long.iloc[lower_index]['longitudes'] + pal_long.iloc[upper_index]['longitudes']) / 2\n",
        "        lower_index = int(i) - 1\n",
        "        upper_index = int(i)\n",
        "        diff_lower = abs(i - int(i))\n",
        "        diff_upper = abs(int(i) - i + 1)\n",
        "        if diff_lower < diff_upper:\n",
        "            cuant= pal_long.iloc[lower_index]['longitudes']\n",
        "        else:\n",
        "            cuant= pal_long.iloc[upper_index]['longitudes']\n",
        "\n",
        "    print(f\"La longitud que representa el cuartil {r} es {cuant}\")\n",
        "print(\"------------------------------------------------------------\\nPara los deciles\\n------------------------------------------------------------\\n\")\n",
        "\n",
        "#por ejemplo los deciles:\n",
        "q=10 #entonces q-1 grupos\n",
        "for r in range(1,q):\n",
        "    i=(r/q)*N_1\n",
        "    if i.is_integer():\n",
        "        cuant =  pal_long.loc[int(i)-1,'longitudes']\n",
        "    else:\n",
        "        # lower_index = int(i) - 1\n",
        "        # upper_index = int(i)\n",
        "        # cuant = (pal_long.iloc[lower_index]['longitudes'] + pal_long.iloc[upper_index]['longitudes']) / 2\n",
        "\n",
        "        lower_index = int(i) - 1\n",
        "        upper_index = int(i)\n",
        "        diff_lower = abs(i - int(i))\n",
        "        diff_upper = abs(int(i) - i + 1)\n",
        "        if diff_lower < diff_upper:\n",
        "            cuant= pal_long.iloc[lower_index]['longitudes']\n",
        "        else:\n",
        "            cuant= pal_long.iloc[upper_index]['longitudes']\n",
        "\n",
        "    print(f\"La longitud que representa el decil {r} es {cuant}\")"
      ],
      "metadata": {
        "id": "fdU9lP0ocubP",
        "cellView": "form"
      },
      "id": "fdU9lP0ocubP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title C√°lculo de cuartiles y deciles usando funci√≥n de Python:\n",
        "# Calculamos los cuantiles: cuartiles\n",
        "cuantiles = [0.25, 0.50, 0.75]\n",
        "resultados_cuantiles = pal_long['longitudes'].quantile(cuantiles, interpolation='nearest')\n",
        "# Mostramos los resultados\n",
        "print(\"\\nCuartiles:\")\n",
        "print(resultados_cuantiles)\n",
        "\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "\n",
        "deciles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "resultados_deciles = pal_long['longitudes'].quantile(deciles, interpolation='nearest')\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Deciles:\")\n",
        "print(resultados_deciles)"
      ],
      "metadata": {
        "id": "xjqpbsfZOYRH",
        "cellView": "form"
      },
      "id": "xjqpbsfZOYRH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cuartiles para una variable por intervalo\n",
        "Si la variable $X$ est√° reducida por intervalos, tomaremos como cuantil r-√©simo de orden $q$ la marca de clase del primer intervalo tal que su frecuencia absoluta acumulada sea mayor o igual a $\\frac{r}{q}(N+1)$.\n",
        "De manera equivalente, tambi√©n podemos obtenerlo buscando el primer intervalo tal que su frecuencia absoluta relativa sea mayor o igual a $\\frac{r}{q}$.\n",
        "Esto es, el intervalo $i$ tal que:\n",
        "\n",
        "$$N_{i} \\geq \\frac{r}{q}(N+1)$$\n",
        "y\n",
        "$$N_{i-1} < \\frac{r}{q}(N+1)$$\n",
        "\n",
        "O de manera equivalente, $F_{i} \\geq \\frac{r}{q} $ y $F_{i-1} < \\frac{r}{q} $\n",
        "\n"
      ],
      "metadata": {
        "id": "C3WfYyPiyMQt"
      },
      "id": "C3WfYyPiyMQt"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3Cmh47t1z8WK"
      },
      "id": "3Cmh47t1z8WK"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### **Ejercicio de cuantiles:** Calcular los cuantiles de datos agrupados por intervalos: El objetivo de este ejercicio es calcular los diferentes cuantiles de la longitud de las palabras del texto que est√° por agregada por intervalos (ver tabla *tabla_frecuencias_eje3*)\n",
        "print(tabla_frecuencias_eje3)"
      ],
      "metadata": {
        "id": "uvF-Y_HAa-F6",
        "cellView": "form"
      },
      "id": "uvF-Y_HAa-F6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Soluci√≥n cuantiles por intervalos: { vertical-output: true }\n",
        "#cuartiles:\n",
        "print(f\"\\nLos cuartiles de los datos agrupados por intervalos son:\\n\")\n",
        "q=4\n",
        "for i in range(1,q):\n",
        "    pto=i/q\n",
        "    q_i=round(tabla_frecuencias_eje3.loc[(tabla_frecuencias_eje3['F_i'] >= pto).idxmax(),\"Marca_de_clase\"])\n",
        "    print(f\"El cuartil {i} de longitud de palabras del texto de prueba es: {q_i}\")\n",
        "\n",
        "\n",
        "print(f\"\\nLos Deciles de los datos agrupados por intervalos son:\\n\")\n",
        "q=10\n",
        "for i in range(1,q):\n",
        "    pto=i/q\n",
        "    q_i=round(tabla_frecuencias_eje3.loc[(tabla_frecuencias_eje3['F_i'] >= pto).idxmax(),\"Marca_de_clase\"])\n",
        "    print(f\"El decil {i} de longitud de palabras del texto de prueba es: {q_i}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PIeRfd9z0Nf4"
      },
      "id": "PIeRfd9z0Nf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## Medidas de dispersi√≥n absoluta:\n",
        "***\n",
        "\n",
        "Cuantifican cu√°nto ***var√≠a*** la variable de estudio (c√≥mo los valores se distinguen de sus valores centrales).\n",
        "\n",
        "* **Desviaci√≥n t√≠pica**:\n",
        "Geom√©tricamente, la **desviaci√≥n t√≠pica** mide lo lejos que est√° la variable de ser constante, en concreto de tomar siempre el valor $\\bar{X}$:\n",
        "\n",
        "$$\\sigma_{X}=\\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_{X})^{2}}$$\n",
        "\n",
        "* **Varianza**:\n",
        "Es definida como el cuadrado de la desviaci√≥n t√≠pica.\n",
        "$$Var(X) = \\sigma_{X}^{2}=\\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\mu_{X})^{2}$$\n",
        "\n",
        "donde $N$ es el tama√±o de la poblaci√≥n y $\\mu_{X}$ es conocida como la media poblacional.\n"
      ],
      "metadata": {
        "id": "Zuxww05_7H8s"
      },
      "id": "Zuxww05_7H8s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¬øC√≥mo se calcula la varianza?\n",
        "\n",
        "Las siguientes expresiones son equivalentes para calcular la varianza, que dependiendo de la informaci√≥n de la que dispongamos nos pueden facilitar su c√°lculo. Esto nos permite definir la varianza como la diferencia de la media de los cuadrados con respecto al cuadrado de la media:\n",
        "\n",
        "\n",
        "$$Var(X) = \\sigma_{X}^{2}=\\frac{1}{N} \\sum_{i=1}^{N}(x_{i}-\\mu_{X})^{2} = \\frac{1}{N}\\sum_{i=1}^{N}X_{i}^{2}-\\mu_{X}^{2} = \\bar{X^{2}}-\\mu_{X}^{2} = \\frac{1}{N}\\Big(\\sum_{i=1}^{N}X_{i}^{2}-\\frac{(\\sum_{i=1}^{N}X_{i})^{2}}{N}\\Big)$$\n",
        "\n",
        "La √∫ltima expresi√≥n es la m√°s recomendable para realizar las cuentas manualmente: requiere la suma y la suma de cuadrados.\n",
        "\n",
        "Si $X$ est√° reducida por intervalos entonces se aproximan $\\sigma_{X}$ y $\\sigma_{X}^{2}$ usando las marcas de clase, como en el caso de la media $\\bar{X}$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ruHXrZJVAKpJ"
      },
      "id": "ruHXrZJVAKpJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ***Ejemplo de c√°lculo de varianza y desviaci√≥n t√≠pica:*** El prop√≥sito de este ejercicio es calcular la varianza y la desviaci√≥n est√°ndar de la longitud de las palabras del texto dado. Utilizaremos el mismo texto de ejemplo de los ejercicios anteriores y realizaremos los c√°lculos paso a paso.\n",
        "display(pal_long[['longitudes']])\n",
        "\n",
        "# Calculamos la media\n",
        "media = sum(longitudes) / len(longitudes)\n",
        "print(\"Media:\", media)\n",
        "\n",
        "# Calculamos la suma de los cuadrados de las diferencias\n",
        "suma_cuadrados_diferencias = sum((x - media) ** 2 for x in longitudes)\n",
        "print(\"Suma de los cuadrados de las diferencias:\", suma_cuadrados_diferencias)\n",
        "\n",
        "# Calculamos la varianza\n",
        "varianza = suma_cuadrados_diferencias / len(longitudes)\n",
        "print(\"Varianza:\", varianza)\n",
        "\n",
        "# Calculamos la desviaci√≥n est√°ndar\n",
        "desviacion_estandar = varianza ** 0.5\n",
        "print(\"Desviaci√≥n est√°ndar:\", desviacion_estandar)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "muRulfIF6OiV",
        "cellView": "form"
      },
      "id": "muRulfIF6OiV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title C√°lculo a trav√©s de funciones de Python (dentro de la librer√≠a Numpy):\n",
        "# Calculamos la varianza y la desviaci√≥n t√≠pica con numpy\n",
        "varianza_np = np.var(longitudes)\n",
        "desviacion_estandar_np = np.std(longitudes)\n",
        "\n",
        "print(\"Varianza (con numpy):\", round(varianza_np,2))\n",
        "print(\"Desviaci√≥n est√°ndar (con numpy):\", round(desviacion_estandar_np,2))"
      ],
      "metadata": {
        "id": "-b_GLOZUY_OH",
        "cellView": "form"
      },
      "id": "-b_GLOZUY_OH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propiedades de la desviaci√≥n t√≠pica y la varianza:\n",
        "\n",
        "Propiedades de la Varianza:\n",
        "\n",
        "* La varianza es una medida no negativa, es decir, $\\sigma^{2}_{X} \\geq 0$ para cualquier variable aleatoria $X$.\n",
        "    \n",
        "* La varianza es cero si y solo si todos los valores de la variable aleatoria son iguales, es decir, $\\sigma_{X}^{2} = 0 \\iff X = c$ para alg√∫n $c \\in \\mathbb{R}$.\n",
        "    \n",
        "* La varianza de una constante multiplicada por una variable aleatoria es igual a la constante al cuadrado multiplicada por la varianza de la variable aleatoria, es decir, $\\sigma_{cX}^{2} =  c^{2}\\sigma^{2}_{X}$.\n",
        "    \n",
        "* La varianza de la suma de dos variables aleatorias independientes es igual a la suma de sus varianzas, es decir, $\\sigma^{2}_{X + Y} = \\sigma^{2}_{X} + \\sigma^{2}_{Y}$ para variables aleatorias $X$ e $Y$ independientes.\n",
        "\n",
        "\n",
        "Propiedades de la Desviaci√≥n T√≠pica:\n",
        "    \n",
        "* Al igual que la varianza, la desviaci√≥n t√≠pica es una medida no negativa, es decir, $\\sigma_{X} \\geq 0$.\n",
        "    \n",
        "* La desviaci√≥n t√≠pica mide la dispersi√≥n de los datos alrededor de la media de la misma manera que la varianza, pero est√° en la misma escala que los datos originales, lo que facilita su interpretaci√≥n.\n",
        "    \n",
        "* Las propiedades de la desviaci√≥n t√≠pica son esencialmente las mismas que las de la varianza, ya que la desviaci√≥n t√≠pica es simplemente la ra√≠z cuadrada de la varianza.\n",
        "\n",
        "***Ejemplo:***\n",
        "\n",
        "Supongamos que tenemos una variable aleatoria $X$ cuyos valores son $1, 2, 3$ con igual probabilidad.\n",
        "\n",
        "Queremos calcular la varianza de $2X$.\n",
        "\n",
        "\n",
        "Primero, calculemos la media de $X$:\n",
        "$$\n",
        "\\bar{X} = \\frac{1+2+3}{3} = 2.\n",
        "$$\n",
        "\n",
        "La varianza de $X$ es:\n",
        "$$\n",
        "Var(X) = E[(X - \\mu_{X})^2] = \\frac{(1-2)^2 + (2-2)^2 + (3-2)^2}{3} = \\frac{2}{3}.\n",
        "$$\n",
        "\n",
        "Aplicando la propiedad, obtenemos:\n",
        "$$\n",
        "Var(2X) = 2^2 \\cdot Var(X) = 4 \\cdot \\frac{2}{3} = \\frac{8}{3}.\n",
        "$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CPeplhRuLVHj"
      },
      "id": "CPeplhRuLVHj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cuasivarianza y cuasidesviaci√≥n t√≠pica\n",
        "La cuasivarianza y la cuasidesviaci√≥n t√≠pica se definen de manera muy similar a la sus versiones *plenas*. La √∫nica diferencia es que, en este caso, se divide por $n-1$, donde $n$ es el tama√±o de la mustra y se usa cuando solo se tiene acceso a una muestra de los datos en lugar de toda la poblaci√≥n.\n",
        "\n",
        "$$S_{X}=\\sqrt{\\frac{1}{(n-1)}\\sum_{i=1}^{n}(X_{i}-\\bar{X})^{2}}$$\n",
        "$$Var(X) = S_{X}^{2}=\\frac{1}{(n-1)}\\sum_{i=1}^{n}(X_{i}-\\bar{X})^{2},$$\n",
        "donde $\\bar{X}$ es la media estimada en la muestra.\n",
        "\n",
        "- Las propiedades son las mismas que en el caso de la varianza y la desviaci√≥n t√≠pica.\n",
        "<!-- <font color='red'>bar</font> -->"
      ],
      "metadata": {
        "id": "Su_QnUuGvsp3"
      },
      "id": "Su_QnUuGvsp3"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calculamos la (cuasi) varianza y la (cuasi) desviaci√≥n t√≠pica con numpy\n",
        "varianza_np = np.var(longitudes, ddof=1) #con ddof=1 es para ajustar el divisor a n-1\n",
        "desviacion_estandar_np = np.std(longitudes, ddof=1)\n",
        "\n",
        "print(\"Varianza (con numpy):\", round(varianza_np,2))\n",
        "print(\"Desviaci√≥n est√°ndar (con numpy):\", round(desviacion_estandar_np,2))\n"
      ],
      "metadata": {
        "id": "BOPuok7PJ2XN",
        "cellView": "form"
      },
      "id": "BOPuok7PJ2XN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## An√°lisis de frecuencia de los N-gramas:\n",
        "***\n",
        "\n",
        "El an√°lisis de frecuencia de los n-gramas es una t√©cnica fundamental en el procesamiento de lenguaje natural (PLN) que se utiliza para analizar la frecuencia de ocurrencia de secuencias de $N$ elementos, conocidas como n-gramas, en un texto. Los n-gramas son ampliamente utilizados en tareas como la modelizaci√≥n del lenguaje, la traducci√≥n autom√°tica, la correcci√≥n ortogr√°fica, entre otros.\n",
        "\n",
        "**Definici√≥n:**\n",
        "Un n-grama es una secuencia contigua de $N$ elementos de un texto o una cadena de caracteres. Los elementos pueden ser palabras, caracteres, s√≠labas, entre otros. Por ejemplo, en la oraci√≥n *El perro corre r√°pidamente*, algunos ejemplos de n-gramas ser√≠an los siguientes:\n",
        "\n",
        "* Unigramas (1-gramas): El, perro, corre, r√°pidamente.\n",
        "* Bigramas (2-gramas): El perro, perro corre, corre r√°pidamente.\n",
        "* Trigramas (3-gramas): El perro corre, perro corre r√°pidamente.\n",
        "\n",
        "\n",
        "**C√°lculo de Frecuencia:**\n",
        "\n",
        "Para calcular la frecuencia de los n-gramas en un texto, se cuentan las ocurrencias de cada n-grama y se registran en una tabla. Luego, se puede calcular la frecuencia relativa de cada n-grama dividiendo el n√∫mero de ocurrencias de ese n-grama por el n√∫mero total de n-gramas en el texto.\n",
        "\n",
        "**Implementaci√≥n en Python:**\n",
        "\n",
        "A continuaci√≥n, se muestra una implementaci√≥n simple en Python para calcular la frecuencia de los n-gramas en un texto utilizando la biblioteca NLTK (Natural Language Toolkit):\n",
        "\n",
        "Este script tomar√° el texto de ejemplo, lo tokenizar√° en palabras, calcular√° los bigramas y mostrar√° la frecuencia de cada bigrama en el texto.\n"
      ],
      "metadata": {
        "id": "y6QUj4YZ3T-F"
      },
      "id": "y6QUj4YZ3T-F"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea frecuencia de distintos **n-gramas** en Python:\n",
        "# Example sentence\n",
        "sentence = \"Natural language processing is a field of study focused on the interactions between human language and computers. Natural language processing is a very important area in AI\"\n",
        "\n",
        "cl_sentence = limpiar_texto(sentence,\"english\")\n",
        "\n",
        "# first get individual words\n",
        "tokenized = cl_sentence.split()\n",
        "\n",
        "#unigramas\n",
        "\n",
        "#trigramas:\n",
        "# and get a list of all the bi-grams\n",
        "esUnigrams = ngrams(tokenized,1)\n",
        "\n",
        "# get the frequency of each bigram in our corpus\n",
        "esUnigramsFreq = collections.Counter(esUnigrams)\n",
        "\n",
        "# what are the ten most popular ngrams in this Spanish corpus?\n",
        "print(f\"Unigramas:\\n{esUnigramsFreq.most_common(10)}\")\n",
        "\n",
        "\n",
        "\n",
        "#bigramas\n",
        "# and get a list of all the bi-grams\n",
        "esBigrams = ngrams(tokenized, 2)\n",
        "\n",
        "# get the frequency of each bigram in our corpus\n",
        "esBigramFreq = collections.Counter(esBigrams)\n",
        "\n",
        "# what are the ten most popular ngrams in this Spanish corpus?\n",
        "esBigramFreq.most_common(10)\n",
        "\n",
        "print(f\"Bigramas:\\n{esBigramFreq.most_common(10)}\")\n",
        "\n",
        "\n",
        "#trigramas:\n",
        "# and get a list of all the bi-grams\n",
        "esTrigrams = ngrams(tokenized, 3)\n",
        "\n",
        "# get the frequency of each bigram in our corpus\n",
        "esTrigramsFreq = collections.Counter(esTrigrams)\n",
        "\n",
        "# what are the ten most popular ngrams in this Spanish corpus?\n",
        "esTrigramsFreq.most_common(10)\n",
        "\n",
        "print(f\"Trigramas:\\n{esTrigramsFreq.most_common(10)}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hkV6n0nySGzb"
      },
      "id": "hkV6n0nySGzb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumen:\n",
        "\n",
        "***\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/resumen_descriptiva.png?raw=1\" alt=\"resumen\" width=\"100%\" height=\"100%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "9S8XG7Ru7Y8G"
      },
      "id": "9S8XG7Ru7Y8G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***"
      ],
      "metadata": {
        "id": "NliUJt0nQyIA"
      },
      "id": "NliUJt0nQyIA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# Probabilidad ¬°La clave!\n",
        "***"
      ],
      "metadata": {
        "id": "tY-CrT1IUku9"
      },
      "id": "tY-CrT1IUku9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/prob.png?raw=1\" alt=\"prob\" width=\"50%\" height=\"50%\">\n",
        "</center>\n",
        "\n",
        "**Motivaci√≥n**\n",
        "\n",
        "Frente a un fen√≥meno aleatorio, el resultado es incierto y su predicci√≥n se vuelve un desaf√≠o. La probabilidad se convierte en nuestra br√∫jula en este territorio de incertidumbre.\n",
        "\n",
        "**Analicemos ejemplos:**\n",
        "\n",
        "# ***¬øCu√°l ser√° el siguiente t√©rmino en una secuencia de palabras generada por un modelo de lenguaje?***\n",
        "\n",
        "Aunque no podemos predecir exactamente qu√© palabra seguir√°, podemos calcular la probabilidad condicional de que una palabra determinada siga a otra dentro del contexto de la secuencia.\n",
        "\n",
        "# ***¬øQu√© tan probable es que un mensaje de texto sea spam?***\n",
        "No podemos afirmar con certeza si un mensaje es spam o no, pero podemos usar t√©cnicas de procesamiento del lenguaje natural, como la clasificaci√≥n de texto, para calcular la probabilidad de que un mensaje en particular sea spam basado en caracter√≠sticas como las palabras utilizadas y el contexto.\n",
        "\n",
        "# ***¬øCu√°l es la probabilidad de que un documento sea relevante para una consulta de b√∫squeda?***\n",
        "Al buscar en un motor de b√∫squeda, no podemos predecir con certeza qu√© documentos ser√°n relevantes para la consulta del usuario. Sin embargo, podemos utilizar algoritmos de procesamiento del lenguaje natural y modelos de recuperaci√≥n de informaci√≥n para calcular la probabilidad de relevancia de un documento en funci√≥n de la coincidencia de palabras clave y la sem√°ntica del texto.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HHmzlP6tcWTf"
      },
      "id": "HHmzlP6tcWTf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceptos:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kOkS8p8Tendr"
      },
      "id": "kOkS8p8Tendr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Distribuci√≥n de probabilidad:**\n",
        "\n",
        "La distribuci√≥n de probabilidad es una funci√≥n matem√°tica que describe las posibles ocurrencias de un evento y la probabilidad asociada a cada una de ellas. En otras palabras, indica c√≥mo se distribuyen las probabilidades entre los diferentes resultados posibles de un fen√≥meno aleatorio.\n",
        "\n",
        "Una **distribuci√≥n de probabilidad** es una funci√≥n $ P: \\{ sucesos \\} \\rightarrow [0,1]$.\n",
        "\n",
        "Denotamos por $\\Omega$ al conjunto total de resultados posibles, donde cada elemento en $ \\Omega$ se llama suceso elemental.\n",
        "El suceso imposible se denota como $\\emptyset$.\n",
        "\n",
        "Un suceso es un conjunto formado mediante la uni√≥n, intersecci√≥n o complementaci√≥n de **sucesos elementales**.\n",
        "\n",
        "Si $A$ es un **suceso**, $P(A)$  es la probabilidad de $A$, donde $ 0 \\leq P(A) \\leq 1$.\n",
        "\n",
        "Para dos sucesos $A$ y $B$:\n",
        "* $A \\cup B $ representa la uni√≥n de $A$ y $B$, se cumple si al menos uno de los dos sucesos ocurre.\n",
        "* $A \\cap B$ representa la intersecci√≥n de $A$ y $B$, se cumple si ambos sucesos ocurren.\n",
        "* $A^c$ es el complemento de $A$: se cumple exactamente cuando $A$ no ocurre.\n",
        "\n",
        "**Propiedades:**\n",
        "Una distribuci√≥n de probabilidad $P(X)$ para una variable aleatoria discreta $X$ debe satisfacer las siguientes propiedades:\n",
        "1. $0 \\leq P(X = x_i) \\leq 1$ para todo valor de $x_i$.\n",
        "2. La suma de las probabilidades para todos los posibles valores de $X$ es igual a 1:\n",
        "$ \\sum_{i} P(X = x_i) = 1 $.\n",
        "\n",
        "Adem√°s:\n",
        "\n",
        "*  El **suceso total** es $P(\\Omega)=1$.\n",
        "*  $P(\\emptyset)=0$"
      ],
      "metadata": {
        "id": "1RvMtf0oYYWk"
      },
      "id": "1RvMtf0oYYWk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regla de Laplace"
      ],
      "metadata": {
        "id": "EcqX30fSYu6_"
      },
      "id": "EcqX30fSYu6_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso en el que los sucesos elementales sean equiprobables, podemos calcular la probabilidad de un suceso $A$ de la siguiente forma:\n",
        "\n",
        "$$P(A)=\\frac{|A|}{|\\Omega|} = \\frac{\\text{# de casos favorables}}{\\text{# de casos posibles}}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "1E5GVENnNNO6"
      },
      "id": "1E5GVENnNNO6"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ***Ejemplo:*** Teniendo en cuenta el texto que venimos trabajando, ¬øCu√°l es la probabilidad de que una palabra elegida al azar tenga longitud mayor o igual a 10?\n",
        "# Dividir el texto en palabras\n",
        "palabras = texto_limpio.split()\n",
        "\n",
        "# Contar cu√°ntas palabras tienen una longitud mayor o igual a 10 caracteres\n",
        "num_palabras_largas = sum(1 for palabra in palabras if len(palabra) >= 10)\n",
        "\n",
        "# Calcular la probabilidad\n",
        "\n",
        "probabilidad = num_palabras_largas / len(palabras)\n",
        "\n",
        "print(\"N√∫mero total de palabras (# de casos posibles):\", len(palabras))\n",
        "print(\"N√∫mero de palabras con longitud mayor o igual a 10 (# de casos favorables):\", num_palabras_largas)\n",
        "print(\"Probabilidad de seleccionar una palabra de longitud mayor o igual a 10:\", probabilidad)"
      ],
      "metadata": {
        "id": "9wwgb5te4Iju",
        "cellView": "form"
      },
      "id": "9wwgb5te4Iju",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Ejercicio:***\n",
        "¬øCu√°l es la probabilidad de que al seleccionar una palabra al azar del texto de ejemplo, comience por la letra *e*? sabiendo que hay 35 palabras, de las 218 que comienzan por e."
      ],
      "metadata": {
        "id": "jcO-PFSIU_Tm"
      },
      "id": "jcO-PFSIU_Tm"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Rta:\n",
        "# Dividir el texto en palabras\n",
        "palabras = texto_limpio.split()\n",
        "# Contar cu√°ntas palabras comienzan con la letra \"e\"\n",
        "num_palabras_e = sum(1 for palabra in palabras if palabra.lower().startswith('e'))\n",
        "\n",
        "# Calcular la probabilidad\n",
        "probabilidad_palabra_e = num_palabras_e / len(palabras)\n",
        "\n",
        "print(\"N√∫mero total de palabras:\", len(palabras))\n",
        "print(\"N√∫mero de palabras que comienzan con 'e':\", num_palabras_e)\n",
        "print(\"Probabilidad de que una palabra comience con 'e':\", probabilidad_palabra_e)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fy1aUg1XbA8W"
      },
      "id": "fy1aUg1XbA8W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Probabilidad condicionada:**\n",
        "\n",
        "Dados dos sucesos, $A$ y $B$, si $n_{A \\cap B}$ es la frecuencia de resultados en los que se cumplen $A$  y $B$ a la vez en $N$ *experimentos*, entonces $\\frac{n_{A \\cap B}}{n_{B}}$ expresa la proporci√≥n de casos en los que sucede $A$ entre los que sucede $B$.\n",
        "\n",
        "Como $$\\frac{n_{A \\cap B}}{n_{B}} = \\frac{n_{A \\cap B}/N}{n_{B}/N} \\xrightarrow[N \\rightarrow +\\infty]{}\\frac{P(A \\cap B)}{P(B)},$$\n",
        "\n",
        "se define la **probabilidad de $A$ condiciona a $B$** como la probabilidad de $A$ si damos por supuesto que sucede $B$, esto es:\n",
        "\n",
        "$$P(A|B)=\\frac{P(A \\cap B)}{P(B)}$$.\n",
        "\n"
      ],
      "metadata": {
        "id": "tVcQ7dPh3-N8"
      },
      "id": "tVcQ7dPh3-N8"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ***Ejemplo:*** Supongamos que queremos calcular la probabilidad de que una palabra seleccionada al azar del texto comience con la letra \"e\", dado que esa palabra tiene una longitud mayor o igual a 10 caracteres. Para calcular esta probabilidad condicionada, primero necesitamos contar el n√∫mero de palabras que cumplen con ambas condiciones (longitud mayor o igual a 10 caracteres y comienzo con \"e\"), y luego dividirlo por el n√∫mero total de palabras que tienen una longitud mayor o igual a 10 caracteres.\n",
        "\n",
        "# Dividir el texto en palabras\n",
        "palabras = texto_limpio.split()\n",
        "\n",
        "# Contar palabras con longitud mayor o igual a 10 caracteres\n",
        "num_palabras_largas = sum(1 for palabra in palabras if len(palabra) >= 10)\n",
        "\n",
        "# Contar palabras que comienzan con \"e\" y tienen longitud mayor o igual a 10 caracteres\n",
        "num_palabras_e_largas = sum(1 for palabra in palabras if len(palabra) >= 10 and palabra.lower().startswith('e'))\n",
        "\n",
        "# Calcular la probabilidad condicionada\n",
        "probabilidad_condicionada = num_palabras_e_largas / num_palabras_largas\n",
        "\n",
        "print(\"N√∫mero total de palabras con longitud mayor o igual a 10:\", num_palabras_largas)\n",
        "print(\"N√∫mero de palabras que comienzan con 'e' y tienen longitud mayor o igual a 10:\", num_palabras_e_largas)\n",
        "print(\"Probabilidad de que una palabra comience con 'e' dado que tiene longitud mayor o igual a 10:\", probabilidad_condicionada)"
      ],
      "metadata": {
        "id": "Hjcch5cNaAlO",
        "cellView": "form"
      },
      "id": "Hjcch5cNaAlO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Ejercicio:***\n",
        "\n",
        "En el texto dado, consideramos las palabras que tienen una longitud menor a 5 caracteres. Si seleccionamos una palabra al azar de entre estas palabras, ¬øcu√°l es la probabilidad de que esa palabra termine con la letra \"s\"?"
      ],
      "metadata": {
        "id": "_cEj8w4_Baxs"
      },
      "id": "_cEj8w4_Baxs"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Rta\n",
        "# Dividir el texto en palabras\n",
        "palabras = texto_limpio.split()\n",
        "\n",
        "# Contar palabras con longitud menor a 5 caracteres\n",
        "num_palabras_cortas = sum(1 for palabra in palabras if len(palabra) < 5)\n",
        "\n",
        "# Contar palabras que terminen con \"s\" y tienen longitud menora 5 caracteres\n",
        "num_palabras_s_cortas = sum(1 for palabra in palabras if len(palabra) < 5 and palabra.lower().endswith('s'))\n",
        "\n",
        "# Calcular la probabilidad condicionada\n",
        "probabilidad_condicionada = num_palabras_s_cortas / num_palabras_cortas\n",
        "\n",
        "print(\"N√∫mero total de palabras con longitud menor a 5:\", num_palabras_cortas)\n",
        "print(\"N√∫mero de palabras que terminan con 's' y tienen longitud menor a 10:\", num_palabras_s_cortas)\n",
        "print(\"Probabilidad de que una palabra termine con 's' dado que tiene longitud menor a 5:\", probabilidad_condicionada)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TNwrpZ6JBCyq"
      },
      "id": "TNwrpZ6JBCyq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propiedades de la probabilidad condicional:\n",
        "\n",
        "   \n",
        "* Independencia: Dos eventos $A$ y $B$ son independientes si y solo si la probabilidad de que ocurra $A$ no se ve afectada por la ocurrencia de $B$, y viceversa. Esto se expresa matem√°ticamente como:\n",
        "\n",
        "$$P(A|B) = P(A) \\quad \\text{y} \\quad P(B|A) = P(B)$$\n",
        "        \n",
        "* Regla del Producto: La probabilidad de la intersecci√≥n de dos eventos $A$ y $B$ puede calcularse utilizando la probabilidad condicionada:\n",
        "\n",
        "$$P(A \\cap B) = P(A|B) \\cdot P(B)$$\n",
        "        \n",
        "* Teorema de Bayes: Es una herramienta poderosa que nos permite actualizar nuestras creencias sobre la ocurrencia de un evento $A$ dado que ha ocurrido otro evento $B$.\n",
        "\n",
        "    Como $$P(A|B)=\\frac{P(A \\cap B)}{P(B)} \\quad \\text{y} \\quad P(B|A)=\\frac{P(A \\cap B)}{P(A)},$$\n",
        "\n",
        "    y\n",
        "    \n",
        "    $$P(A \\cap B) =P(B) \\cdot P(A|B) = P(A) \\cdot P(B|A)$$\n",
        "\n",
        "    Entonces:\n",
        "    \n",
        "    $$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
        "    "
      ],
      "metadata": {
        "id": "5Uwl7QJHCuX4"
      },
      "id": "5Uwl7QJHCuX4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Variables aleatorias:**\n",
        "\n",
        "Una variable aleatoria (v.a.) es como un *contenedor* de resultados posibles en un experimento. Piensa en ella como una herramienta que nos ayuda a asignar n√∫meros a los resultados de un evento que no es fijo (aleatorio).\n",
        "\n",
        "Por ejemplo, imagina que est√°s lanzando un dado. Cada vez que lo lanzas, obtienes un n√∫mero diferente. Ese n√∫mero que obtienes, ya sea un 1, un 2, un 3, hasta un 6, es el valor de tu variable aleatoria para ese lanzamiento.\n",
        "\n",
        "Si est√°s midiendo la temperatura de una habitaci√≥n y obtienes diferentes lecturas cada vez que tomas la temperatura, entonces esa temperatura medida es una variable aleatoria. Puedes obtener 25 grados, 25.5 grados, 26 grados, etc.\n",
        "\n",
        "En resumen, una variable aleatoria es una manera de representar num√©ricamente los resultados de un experimento aleatorio. No es solo un n√∫mero aleatorio, sino una manera de organizar y entender la informaci√≥n que obtenemos de nuestros experimentos.\n",
        "\n",
        "\n",
        "**Formalmente:**\n",
        "\n",
        "En t√©rminos m√°s formales, una (v.a.) es una funci√≥n que asigna un n√∫mero real a cada resultado posible de un experimento aleatorio. Si denotamos la variable aleatoria como $X$, entonces para cada resultado $x$ del experimento, $X$ asigna un valor que es un n√∫mero real ($x \\in \\mathbb{R}$):\n",
        "\n",
        "$$X: \\Omega \\rightarrow \\mathbb{R}$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWNDnM_OIkNV"
      },
      "id": "ZWNDnM_OIkNV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables aleatorias discretas:\n",
        "\n",
        "Una v.a. es discreta si la cantidad de valores que puede tomar es numerable:\n",
        "$$x_{1}, x_{2}, x_{3},...$$\n",
        "\n",
        "En una v.a. discreta $ p_{k}= P(X=k)$ es la funci√≥n de probabilidad o de masa. Se cumple $\\sum p_{x_{i}}=1$, esto es, las probabilidades de todos los valores que la v.a. discreta puede tomar suman 1.\n",
        "\n",
        "***Ejemplo:***\n",
        "\n",
        "- Variable de Bernulli. $$X \\thicksim B(p), 0 < p < 1,$$\n",
        "    de manera que\n",
        "   \n",
        "   $$ X = \\begin{cases}\n",
        "  1 & \\text{ con probabilidad } p \\\\\n",
        "  0 & \\text{ con probabilidad } (1-p)\n",
        "\\end{cases}$$\n",
        "\n",
        "Esto es, $p_{1}=p$ y $p_{0}=1-p$\n",
        "\n",
        "**En el an√°lisis del sentimiento**, determinar si la cr√≠tica de una pel√≠cula es positiva (1) o negativa (0) representa un ensayo Bernoulli.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nAASqdGNLgJN"
      },
      "id": "nAASqdGNLgJN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables aleatorias continuas:\n",
        "\n",
        "Una v.a. **continua** $X$ cumple que para todo n√∫mero $k$, la probabilidad de que $X$ lo tome es nula, esto es $P(X=k)=0$. La probabilidad que interesa es la de que tome valores en cualquier intervalo, esto es:\n",
        "* La probabilidad de (a,b) es $P(a < x < b)$, que es la misma que la de $[a,b]$, $[a,b)$ √≥ $(a,b]$.\n",
        "* La probabilidad de $(a, +\\infty)$ es $P(X>a)$.\n",
        "* La probabilidad de $(-\\infty, a)$ es $P(X<a)$.\n",
        "\n",
        "***Ejemplos:***\n"
      ],
      "metadata": {
        "id": "oR8T8AmBjTIT"
      },
      "id": "oR8T8AmBjTIT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funci√≥n de densidad:\n",
        "\n",
        "Dada $X$ una v.a. continua, una funci√≥n $f\\geq0$ es la funci√≥n de densidad de $X$ si la probabilidad de $(a,b)$ es igual al √°rea de la regi√≥n limitada por la gr√°fica $y=f(x)$, y las rectas $y=0$, $x=a$ y $x=b$.\n"
      ],
      "metadata": {
        "id": "xrAX_meZrHND"
      },
      "id": "xrAX_meZrHND"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title funci√≥n de densidad { vertical-output: true, display-mode: \"form\" }\n",
        "# Definir la funci√≥n de densidad de probabilidad (PDF)\n",
        "def f(x):\n",
        "    # Puedes definir tu propia funci√≥n de densidad aqu√≠\n",
        "    funcion= x * np.exp(-x**2 / 3) / np.sqrt(2 * np.pi)\n",
        "    return funcion\n",
        "\n",
        "# Definir los l√≠mites del intervalo [a, b]\n",
        "a = 0.2\n",
        "b = 3\n",
        "\n",
        "# Generar valores de x en el intervalo [a, b]\n",
        "x_values = np.linspace(a, b, 1000)\n",
        "\n",
        "# Calcular los valores de y = f(x)\n",
        "y_values = f(x_values)\n",
        "\n",
        "# Crear la gr√°fica\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Graficar la funci√≥n de densidad de probabilidad (PDF)\n",
        "plt.plot(x_values, y_values, 'b-', linewidth=2)\n",
        "\n",
        "# Rellenar el √°rea bajo la curva entre x=a y x=b\n",
        "plt.fill_between(x_values, 0.05, y_values, where=(x_values >= a) & (x_values <= b-1), color='skyblue', alpha=0.5)\n",
        "\n",
        "# L√≠neas verticales en x=a y x=b\n",
        "plt.axvline(x=a, color='gray', linestyle='--', linewidth=1)\n",
        "plt.axvline(x=b-1, color='gray', linestyle='--', linewidth=1)\n",
        "\n",
        "# L√≠neas horizontal en y=0\n",
        "plt.axhline(y=0.081, xmin=0, xmax=1.6, color='gray', linestyle='--', linewidth=1)\n",
        "\n",
        "# Eliminar los ticks de los ejes x e y\n",
        "plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
        "plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
        "\n",
        "# Agregar texto en x=-2 (x=a) y x=2 (x=b)\n",
        "plt.text(a, 0.07, 'x=a', ha='center', va='center', color='black', fontsize=12)\n",
        "plt.text(b-1, 0.07, 'x=b', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "plt.text(0.7, 0.275, 'y=f(x)', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "plt.text(1.15, 0.25, 'P(a < X < b)', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "plt.text(2.9, 0.085, 'y=0', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "\n",
        "# Establecer l√≠mites y mostrar la gr√°fica\n",
        "plt.ylim(0.08, 0.3)  # Ajustar el l√≠mite y\n",
        "plt.xlim(0, np.max(x_values))  # Ajustar el l√≠mite x\n",
        "# Mostrar la gr√°fica\n",
        "plt.grid(True)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6nZMNHxLsT-Q"
      },
      "id": "6nZMNHxLsT-Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propiedades:\n",
        "\n",
        "* El √°rea total entre $y=0$ e $y=f(x)$ es igual a 1.\n",
        "* El √°rea a la derecha de $x=b$ delimitada por $y=0$ e $y=f(x)$ es $P(X > b)$.\n",
        "* El √°rea a la izquierda de $x=a$ delimitada por $y=0$ e $y=f(x)$ es $P(X < a)$.\n"
      ],
      "metadata": {
        "id": "7C0QTJ7xxMcK"
      },
      "id": "7C0QTJ7xxMcK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribuci√≥n normal est√°ndar:\n",
        "La d.p. continua m√°s importante es la **distribuci√≥n normal est√°ndar** $N(0,1)$, esto es, la distribuci√≥n normal de *media* 0 y *desviaci√≥n t√≠pica* 1.\n",
        "\n",
        "Su funci√≥n de densidad tiene la forma llamada ***campana de Gauss***, y es sim√©trica respecto a $x=0$.\n",
        "\n",
        "**Nota:**\n",
        "Una variable gen√©rica con distribuci√≥n $N(0,1)$ se suele denotar $Z$ (en lugar de $X$), y escribimos $Z \\sim N(0,1)$.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5ryaEC4yM_T"
      },
      "id": "Y5ryaEC4yM_T"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea distribuci√≥n normal est√°ndar { vertical-output: true }\n",
        "def f(x):\n",
        "    # Puedes definir tu propia funci√≥n de densidad aqu√≠\n",
        "    # Por ejemplo, una distribuci√≥n normal est√°ndar\n",
        "    return np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)\n",
        "\n",
        "# Definir los l√≠mites del intervalo [a, b]\n",
        "a = -2\n",
        "b = 2\n",
        "\n",
        "# Generar valores de x en el intervalo [a, b]\n",
        "x_values = np.linspace(a, b, 1000)\n",
        "\n",
        "# Calcular los valores de y = f(x)\n",
        "y_values = f(x_values)\n",
        "\n",
        "# Crear la gr√°fica\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Graficar la funci√≥n de densidad de probabilidad (PDF)\n",
        "plt.plot(x_values, y_values, 'b-', linewidth=2)\n",
        "\n",
        "# L√≠neas horizontal en y=0\n",
        "plt.hlines(y=0.055, xmin=-2, xmax=2, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "\n",
        "# L√≠neas verticales en x=a y x=b\n",
        "plt.axvline(x=0, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "# Eliminar los ticks de los ejes x e y\n",
        "plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
        "plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
        "\n",
        "plt.text(2.15, 0.055, 'y=0', ha='center', va='center', color='black', fontsize=12)\n",
        "plt.text(-0.01, 0.03, 'x=0', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "# Mostrar la gr√°fica\n",
        "plt.grid(True)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E-lcrD6Fyoao"
      },
      "id": "E-lcrD6Fyoao",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- ### Variables aleatorias continua:\n",
        "\n",
        "Una v.a. continua ùëã cumple que para todo n√∫mero ùëò, la probabilidad de que ùëã lo tome es nula, esto es ùëÉ(ùëã=ùëò)=0. La probabilidad que interesa es la de que tome valores en cualquier intervalo, esto es:\n",
        "La probabilidad de (ùëé, ùëè) es ùëÉ(ùëé<ùëã<ùëè), que es la misma que la de [ùëé, ùëè), (ùëé, ùëè] o [ùëé, ùëè].\n",
        "La probabilidad de (ùëé,+‚àû) es ùëÉ(ùëã>ùëé).\n",
        "La probabilidad de (‚àí‚àû, ùëé) es ùëÉ(ùëã<ùëé) -->"
      ],
      "metadata": {
        "id": "r6_5sH3vNxiy"
      },
      "id": "r6_5sH3vNxiy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribuci√≥n normal:\n",
        "Si $Z \\thicksim N(0,1)$, dados dos valores $\\mu$ y $\\sigma (\\sigma > 0)$ la v.a. $X = \\mu + \\sigma Z$  tiene la distribuci√≥n normal $N(\\mu,\\sigma)$ de media $\\mu$ y desviaci√≥n t√≠pica $\\sigma$. Se escribe $X \\thicksim N(\\mu,\\sigma)$.\n",
        "\n",
        "Su funci√≥n de densidad es tambi√©n una campana de Gauss, centrada en $x=\\mu$ y sim√©trica respecto a esta recta. En $\\mu-\\sigma$ y $\\mu+\\sigma$ est√°n los puntos de inflexi√≥n.\n"
      ],
      "metadata": {
        "id": "eCHlRgvRC6LY"
      },
      "id": "eCHlRgvRC6LY"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea distribuci√≥n normal est√°ndar { vertical-output: true }\n",
        "def f(x):\n",
        "    # Puedes definir tu propia funci√≥n de densidad aqu√≠\n",
        "    # Por ejemplo, una distribuci√≥n normal est√°ndar\n",
        "    return np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)\n",
        "\n",
        "# Definir los l√≠mites del intervalo [a, b]\n",
        "a = -2\n",
        "b = 2\n",
        "\n",
        "# Generar valores de x en el intervalo [a, b]\n",
        "x_values = np.linspace(a, b, 1000)\n",
        "\n",
        "# Calcular los valores de y = f(x)\n",
        "y_values = f(x_values)\n",
        "\n",
        "# Crear la gr√°fica\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Graficar la funci√≥n de densidad de probabilidad (PDF)\n",
        "plt.plot(x_values, y_values, 'b-', linewidth=2)\n",
        "\n",
        "\n",
        "# Rellenar el √°rea bajo la curva entre x=a y x=b\n",
        "plt.fill_between(x_values, 0, y_values, where=(x_values >= a+1) & (x_values <= b-1), color='skyblue', alpha=0.2)\n",
        "\n",
        "\n",
        "\n",
        "# L√≠neas verticales en x=a y x=b\n",
        "plt.axvline(x=0, color='blue', linestyle='--', linewidth=1)\n",
        "plt.axvline(x=-1, color='blue', linestyle='--', linewidth=1)\n",
        "plt.axvline(x=1, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "# L√≠neas horizontal en y=0\n",
        "plt.hlines(y=0.082, xmin=-1.79, xmax=1.79, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "\n",
        "# Eliminar los ticks de los ejes x e y\n",
        "plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
        "plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(0, 0.4), xytext=(0.45, 0.4),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "\n",
        "plt.annotate('', xy=(0.55, 0.4), xytext=(1, 0.4),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "plt.text(0.5, 0.4, '$\\sigma$', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "plt.text(2, 0.082, 'y=0', ha='center', va='center', color='black', fontsize=12)\n",
        "plt.text(-0.01, 0.07, f'$x=\\mu$', ha='center', va='center', color='black', fontsize=12)\n",
        "plt.text(-1, 0.07, f'$x=\\mu-\\sigma$', ha='center', va='center', color='black', fontsize=12)\n",
        "plt.text(1, 0.07, f'$x=\\mu+\\sigma$', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "plt.text(-0.01, 0.15, f'$P(\\mu-\\sigma<X<\\mu+\\sigma)= 0.6827$ (‚âà 2/3)', ha='center', va='center', color='black', fontsize=11)\n",
        "\n",
        "plt.ylim(0.08, 0.45)  # Ajustar el l√≠mite y\n",
        "\n",
        "\n",
        "# Mostrar la gr√°fica\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nS2im2unNy5c",
        "cellView": "form"
      },
      "id": "nS2im2unNy5c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propiedades de la distribuci√≥n normal:\n",
        "\n",
        "Dada una v.a. $X$ (normal o no) de media $\\mu$ y desviaci√≥n t√≠pica $\\sigma$ la probabilidad de que $X$ tome un valor que se aleje de su media una distancia inferior a $k$ veces su desviaci√≥n t√≠pica se expresa:\n",
        "\n",
        "$$P(|X-\\mu|<k \\sigma) = P(-k\\sigma <X-\\mu < k\\sigma)=P(\\mu-k\\sigma<X<\\mu+k\\sigma)$$\n",
        "\n",
        "\n",
        "Dada $ X \\thicksim N(\\mu, \\sigma)$, destacamos las siguientes probabilidades:\n",
        "\n",
        "* $P(\\mu-\\sigma<X<\\mu+\\sigma)= 0.6827$, por lo tanto, algo m√°s de 2 de cada 3 veces el valor de una *distribuci√≥n normal* no se aleja de la media m√°s de 1 desviaci√≥n t√≠pica $(2/3 = 0.6)$;\n",
        "\n",
        "* $P(\\mu -2\\sigma < X < \\mu+2\\sigma)=0.9545$,  por lo tanto, algo m√°s del 95% de las veces el valor de una distribuci√≥n normal no se aleja de la media m√°s de 2 desviaciones t√≠picas;\n",
        "\n",
        "* $P(\\mu -3\\sigma < X < \\mu+3\\sigma)=0.9973$, por lo tanto, es muy probable que el valor de una distribuci√≥n normal no se aleje de la media m√°s de 3 desviaciones t√≠picas.\n",
        "\n",
        "* Rec√≠procamente, si $X \\thicksim N(\\mu, \\sigma)$ entonces su tipificada\n",
        "$Z=(X-\\mu)/\\sigma$ cumple que $Z \\thicksim N(0, 1)$. Esto es, al tipificar una distribuci√≥n normal obtenemos la distribuci√≥n normal est√°ndar.\n",
        "\n",
        "    La distribuci√≥n normal aparece con frecuencia en amplios campos de la investigaci√≥n. Es una d.p. muy interesante ya que, hablando informalmente, si el resultado de la variable a estudiar viene dado por la suma de un gran n√∫mero de variables id√©nticas e independientes (que seguramente no sabremos medir) es de esperar que la d.p. resultante sea muy aproximadamente normal.\n",
        "\n"
      ],
      "metadata": {
        "id": "KE0aIA26EXD-"
      },
      "id": "KE0aIA26EXD-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribuci√≥n $t$ de student:\n",
        "\n",
        "La $t$ de Student con $n$ grados de libertad $n=(1,2,3,...)$ es una distribuci√≥n continua. Si una v.a. $T$ sigue una distribuci√≥n $t$ de Student con $n$ grados de libertad, se escribe $T \\thicksim t_{n}$.\n",
        "\n",
        "Como $N(0,1)$, $t_{n}$ est√° centrada en ùë•$x=0$ y es sim√©trica con respecto a esta recta.\n",
        "Se tiene $$t_{n} \\xrightarrow[N \\rightarrow +\\infty]{} N(0,1)$$.\n",
        "\n",
        "Es una d.p. que se usa para hacer inferencia sobre la media. Dadas $X_{1}, X_{2}, ..., X_{n}$ variables aleatorias independientes con una misma distribuci√≥n normal $N(\\mu,\\sigma)$, con media muestral $\\bar{X}$ y cuasidesviaci√≥n t√≠pica $S_{X}$, entonces:\n",
        "\n",
        "$$\\frac{\\bar{X}-\\mu}{S_{X}/\\sqrt{n}}\\thicksim t_{n-1}$$"
      ],
      "metadata": {
        "id": "mvaFnapKbrEZ"
      },
      "id": "mvaFnapKbrEZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea distribuci√≥n t de student\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "from scipy.stats import t\n",
        "\n",
        "# Definir el rango para x\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "\n",
        "# Grados de libertad para las distribuciones t de Student\n",
        "grados_de_libertad = [1, 2, 3, 4, 5,6,7]  # A√±ad√≠ 1000 como infinito\n",
        "\n",
        "# Crear una nueva figura\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Graficar las distribuciones t de Student para diferentes grados de libertad\n",
        "for df in grados_de_libertad[:-1]:\n",
        "    plt.plot(x, t.pdf(x, df), label=f'{df}', linestyle=\"--\")\n",
        "plt.plot(x, t.pdf(x, 10000000000), label=f'$+\\infty$', linestyle=\"-\", color=\"black\")\n",
        "\n",
        "# Agregar texto en x=0 que muestra la media\n",
        "plt.text(0, -0.03, 'x=0', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "# Agregar texto en x=0 que muestra la media\n",
        "plt.text(5.5, 0, 'y=0', ha='center', va='center', color='black', fontsize=12)\n",
        "\n",
        "# Eliminar los ticks de los ejes x e y\n",
        "plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
        "plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
        "\n",
        "# L√≠neas verticales en x=a y x=b\n",
        "plt.axvline(x=0, color='pink', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# L√≠neas verticales en x=a y x=b\n",
        "plt.axhline(y=0, color='pink', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# A√±adir t√≠tulo y leyenda\n",
        "plt.title('Distribuci√≥n t de Student con diferentes grados de libertad')\n",
        "plt.legend(title=\"Grados de libertad\")\n",
        "\n",
        "# Mostrar la gr√°fica\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Brri9EkjOPaF",
        "cellView": "form"
      },
      "id": "Brri9EkjOPaF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regla de la cadena de la probabilidad:\n",
        "\n",
        "La regla de la cadena establece que la probabilidad conjunta de varios eventos condicionales puede calcularse multiplicando las probabilidades condicionales de cada evento dado el conjunto de eventos anteriores.\n",
        "\n",
        "\n",
        "$$P(A_1 \\cap A_2 \\cap A_3 \\cap \\ldots \\cap A_n) = P(A_1) \\cdot P(A_2 | A_1) \\cdot P(A_3 | A_1 \\cap A_2) \\cdot \\ldots \\cdot P(A_n | A_1 \\cap A_2 \\cap \\ldots \\cap A_{n-1}),$$\n",
        "\n",
        "donde $P(A_{i})$ es la probabilidad del evento $A_{i}$ y $P(A_j | A_1 \\cap A_2 \\cap \\ldots \\cap A_{j-1})$ es la probabilidad condicional del evento $A_{j}$, dado que los eventos $A_{1}, A_{2}, \\ldots, A_{j-1}$ han ocurrido.\n",
        "\n",
        "\n",
        "**Supongamos** que tenemos un modelo de lenguaje que intenta predecir la probabilidad de una oraci√≥n dada.\n",
        "Para simplificar, consideremos la oraci√≥n ***El gato negro est√° durmiendo***.\n",
        "\n",
        "Digamos que las palabras en la oraci√≥n se representan como $w_1, w_2, w_3, w_4, w_5$, donde:\n",
        "\n",
        "\n",
        "\n",
        "*   $w_1$ es *El*\n",
        "*   $w_2$ es *gato*\n",
        "*   $w_3$ es *negro*\n",
        "*   $w_4$ es *esta*\n",
        "*   $w_5$ es *durmiendo*\n",
        "\n",
        "\n",
        "\n",
        "Para calcular la probabilidad conjunta de esta oraci√≥n, podemos aplicar la regla de la cadena de la probabilidad descomponiendo la probabilidad de cada palabra dada la secuencia de palabras anteriores.\n",
        "$$P(w_1, w_2, w_3, w_4, w_5) = P(w_1) \\cdot P(w_2 | w_1) \\cdot P(w_3 | w_1, w_2) \\cdot P(w_4 | w_1, w_2, w_3) \\cdot P(w_5 | w_1, w_2, w_3, w_4)$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sb0BSz6sc_pf"
      },
      "id": "Sb0BSz6sc_pf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***"
      ],
      "metadata": {
        "id": "1FbauPe_xqzl"
      },
      "id": "1FbauPe_xqzl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# Inferencia\n",
        "***"
      ],
      "metadata": {
        "id": "yIGpkXYjxr7v"
      },
      "id": "yIGpkXYjxr7v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/ednavivianasegura/Curso_PLN/blob/main/inferencia.png?raw=1\" alt=\"inferencia\" width=\"50%\" height=\"50%\">  \n",
        "</center>"
      ],
      "metadata": {
        "id": "rCqOVy82xQAs"
      },
      "id": "rCqOVy82xQAs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para estudiar alg√∫n aspecto de la distribuci√≥n de una variable $X$, tomamos una muestra de $n$ valores independientes de $X: x_{1}, x_{2}, ... , x_{n}$. En ***Estad√≠stica Inferencial*** se estudia qu√© afirmaciones podemos hacer sobre los aspectos que nos interesan de $X$, y con qu√© fiabilidad, en base a los valores de la muestra. La muestra puede consistir, por ejemplo, en los datos de $n$ personas encuestadas o los resultados de $n$ mediciones experimentales.\n",
        "\n",
        "Abordaremos dos aspectos:\n",
        "\n",
        "* **La media:** por ejemplo, ¬øpodemos afirmar que la palabra \"tecnolog√≠a\" aparece en promedio 10 veces en los art√≠culos de tecnolog√≠a?\n",
        "* **La proporci√≥n:** por ejemplo, ¬øpodemos afirmar que la un tercio de los documentos relacionados con la pol√≠tica mencionan al partido que se encuentra actualmente en el poder?"
      ],
      "metadata": {
        "id": "4P4kA8_9x2F2"
      },
      "id": "4P4kA8_9x2F2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencia sobre la media\n",
        "\n",
        "Sabemos (o suponemos) que la poblaci√≥n $X$ es normal, $X \\thicksim N(\\mu, \\sigma)$. El valor $\\mu$ es la media poblacional, y nos restringiremos a afirmaciones sobre $\\mu$. A $\\sigma$ se le llama desviaci√≥n t√≠pica poblacional.\n",
        "\n",
        "Como condiciones de validez, deben cumplirse que los casos $X_{i}$ sean independientes (el valor de cada uno no tiene influencia en los dem√°s) y para cada $i$ùëñ, $X_{i} \\thicksim N(\\mu, \\sigma)$.\n",
        "\n",
        "La **media muestral** es\n",
        "$$ \\bar{X}= \\frac{1}{n} \\sum_{i=1}^{n}X_{i}, $$\n",
        "y la **cuasidesviaci√≥n t√≠pica muestral** es\n",
        "\n",
        "$$S_{X}=\\sqrt{\\frac{1}{(n-1)}\\sum_{i=1}^{n}(X_{i}-\\bar{X})^{2}}$$\n",
        "\n",
        "La base de nuestra inferencia es que, como indicamos al tratar la distribuci√≥n normal y la distribuc√≠n $t$ de student,\n",
        "\n",
        "$$\\frac{\\bar{X}-\\mu}{S_{X}/\\sqrt{n}}\\thicksim t_{n-1}$$\n",
        "\n",
        "Obviamente $\\frac{\\bar{X}-\\mu}{S_{X}/\\sqrt{n}}$ es una variable aleatoria, su valor depende de nuestra muestra"
      ],
      "metadata": {
        "id": "I_ixiJbT0ihJ"
      },
      "id": "I_ixiJbT0ihJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencia sobre la proporci√≥n\n",
        "\n",
        "Estudiamos una caracter√≠stica. La probabilidad de que un caso aleatoriamente elegido la cumpla es $p$, la proporci√≥n poblacional. En una muestra de $n$ individuos (casos) la cumplen $k$, y $\\hat{p}=\\frac{k}{n}$ es la **proporci√≥n muestral**. La base de nuestra inferencia es que, si $n$ es grande,\n",
        "\n",
        "\n",
        "$$\\frac{\\hat{p}-p}{\\sqrt{\\frac{p(1-p)}{n}}} \\underset{\\text{aprox}}{\\sim} N(0,1) $$\n",
        "\n",
        "Adem√°s se deben cumplir las siguientes condiciones de validez:\n",
        "\n",
        "* La muestra es ***independiente y representativa*** (en los casos elegidos esperamos que la probabilidad de cumplir la caracter√≠stica sea efectivamente la proporci√≥n muestral).\n",
        "\n",
        "* O bien $n \\geq 30$; o bien $np \\geq 5$ y $n(1-p)\\geq 5$.\n",
        "\n",
        "  Esto significa que la aproximaci√≥n es mala cuando $p \\approx 0$ o $p \\approx 1$. Como no conocemos $p$ esta condici√≥n la sustituimos por $n \\hat{p} = k \\geq 5 $ y $n(1-\\hat{p})=n-k \\geq 5.$"
      ],
      "metadata": {
        "id": "MWPw4Xem2yak"
      },
      "id": "MWPw4Xem2yak"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados de inferencia\n",
        "\n",
        "Nos centramos en tres tipos de inferencia, que realizaremos para la media y para la proporci√≥n:\n",
        "* intervalos de confianza\n",
        "* contrastes de hip√≥tesis\n",
        "* tama√±o de la muestra\n",
        "\n",
        "Estos resultados depender√°n de la fiabilidad establecida, que se expresa mediante el nivel de confianza como $1-\\alpha$ donde $\\alpha$ (que suele representar una probabilidad peque√±a) es el nivel de significaci√≥n.\n",
        "\n",
        "Habitualmente:\n",
        "* $\\alpha = 0.1 $, por lo tanto $1-\\alpha = 0.9$, lo que indica que se tiene el $90\\%$ de confianza.\n",
        "\n",
        "* $\\alpha = 0.05$, por lo tanto $1-\\alpha = 0.95$, lo que indica que se tiene el $95\\%$ de confianza.\n",
        "\n",
        "* $\\alpha = 0.01$, por lo tanto $1-\\alpha = 0.99$, lo que indica que se tiene el $99\\%$ de confianza.\n",
        "\n"
      ],
      "metadata": {
        "id": "CqaYJjIF6E2X"
      },
      "id": "CqaYJjIF6E2X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intervalos de confianza"
      ],
      "metadata": {
        "id": "WLW4QsRD6_pM"
      },
      "id": "WLW4QsRD6_pM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intervalo de confianza para la media\n",
        "\n",
        "Para obtener el intervalo de confianza para la media de una poblaci√≥n normal con nivel de confianza $1-\\alpha$ usamos que\n",
        "\n",
        "$$\\frac{\\bar{X}-\\mu}{S_{X}/\\sqrt{n}}\\thicksim t_{n-1}$$\n",
        "\n",
        "\n",
        "$$1- \\alpha = P\\Big( -t_{n-1;\\alpha/2} < \\frac{\\bar{X}-\\mu}{S_{X}/\\sqrt{n}}\\thicksim t_{n-1} < t_{n-1;\\alpha/2}\\Big)$$\n",
        "\n",
        "despejamos $\\mu$ y llamamos como error muestral a\n",
        "\n",
        "$$EM= t_{n-1;\\alpha/2}S_{X}/\\sqrt{n}$$\n",
        "\n",
        "Entonces:\n",
        "\n",
        "\\begin{align*}\n",
        "1-\\alpha &= P(-EM < \\bar{X} - \\mu < \\bar{X} + EM) \\\\\n",
        "&= P(\\bar{X} -EM < \\mu < \\bar{X} + EM) \\\\\n",
        "&= P(\\mu \\in (\\bar{X} -EM,\\bar{X} +EM))\n",
        "\\end{align*}\n",
        "\n",
        "El valor $1-\\alpha$ representa la probabilidad de que el intervalo dado (en la formula) contenga el verdadero valor del par√°metro $\\mu$."
      ],
      "metadata": {
        "id": "xE84EYJx7Cvs"
      },
      "id": "xE84EYJx7Cvs"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea grafico intervalo para la media\n",
        "# Par√°metros\n",
        "n = 100  # Tama√±o de la muestra\n",
        "alpha = 0.05  # Nivel de confianza\n",
        "\n",
        "# C√°lculo de los valores cr√≠ticos de la distribuci√≥n t de Student\n",
        "t_left = -t.ppf(1 - alpha / 2, n - 1)\n",
        "t_right = t.ppf(1 - alpha / 2, n - 1)\n",
        "\n",
        "# Definir el rango para la gr√°fica\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = t.pdf(x, n - 1)\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, 'b-')\n",
        "# Rellenar el √°rea bajo la curva\n",
        "plt.fill_between(x, y, where=(x >= -2) & (x <= 2), color='lightblue', alpha=0.5)\n",
        "\n",
        "# L√≠neas verticales y etiquetas\n",
        "plt.axvline(0, color='red', linestyle='--', linewidth=0.3)\n",
        "\n",
        "plt.axhline(0, color='blue', linestyle='--', linewidth=0.3)\n",
        "\n",
        "plt.axvline(t_left, color='red', linestyle='--')\n",
        "plt.text(t_left, -0.01, r'$-t_{n-1,\\alpha/2}$', ha='right', va='bottom', color='red')\n",
        "plt.axvline(t_right, color='red', linestyle='--')\n",
        "plt.text(t_right, -0.01, r'$t_{n-1,\\alpha/2}$', ha='left', va='bottom', color='red')\n",
        "\n",
        "plt.text(0, -0.01, '0', ha='center', va='bottom', color='black')\n",
        "plt.text(0, 0.25, r'$1-\\alpha$', ha='center', va='bottom', color='red')\n",
        "\n",
        "plt.text(-2.5, 0.25, r'$-\\alpha/2$', ha='center', va='bottom', color='red')\n",
        "\n",
        "plt.text(2.5, 0.25, r'$\\alpha/2$', ha='center', va='bottom', color='red')\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.25), xytext=(2, 0.25),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.25), xytext=(-3, 0.25),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-'))\n",
        "\n",
        "plt.annotate('', xy=(3, 0.25), xytext=(2, 0.25),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='-|>'))\n",
        "\n",
        "plt.title('Intervalo de Confianza para la Media')\n",
        "plt.grid(True)\n",
        "plt.axis('off')\n",
        "# Mostrar la gr√°fica\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mNHO-JroG2wS",
        "cellView": "form"
      },
      "id": "mNHO-JroG2wS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por lo tanto, el intervalo de confianza para media poblacional $\\mu$ con una fiabilidad de $(1-\\alpha)\\times 100 \\%$ es:\n",
        "\n",
        "$$IC_{1-\\alpha} (\\mu) = \\Big(\\bar{X}-t_{n-1\\;\\alpha/2}\\frac{S_{X}}{\\sqrt{n}},\\bar{X}+t_{n-1\\;\\alpha/2}\\frac{S_{X}}{\\sqrt{n}}\\Big)=\\Big( \\bar{X} \\pm t_{n-1\\;\\alpha/2}\\frac{S_{X}}{\\sqrt{n}}\\Big)$$\n",
        "\n",
        "El error muestral es lo que la media poblacional $\\mu$ puede distanciarse de la media muestral $\\bar{X}$ con el nivel de confianza establecido. En la expresi√≥n $EM=t_{n-1;\\alpha/2}\\frac{S_{X}}{\\sqrt{n}}$ tenemos que:\n",
        "\n",
        "* A menor $S_{X}$, menor $EM$. Esto significa que si la muestra es poco dispersa (presenta pocas variaciones), entonces es m√°s probable que $\\bar{X}$ se acerque a $\\mu$.\n",
        "\n",
        "* A mayor tama√±o de la muestra $n$, menor $EM$. Obviamente, si el denominador es mayor, el $EM$ ser√° menor. Esto significa que una muestra muy numerosa nos da m√°s informaci√≥n sobre la poblaci√≥n.\n",
        "\n",
        "* A menor $\\alpha$, mayor $EM$. Con un intervalo m√°s amplio tendremos m√°s garant√≠as de *acertar*, lo que se consigue con un mayor nivel de confianza $1-\\alpha$.\n"
      ],
      "metadata": {
        "id": "jlbkeD3_7VZC"
      },
      "id": "jlbkeD3_7VZC"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea figura intervalo de confianza para la media\n",
        "plt.figure(figsize=(6,2))\n",
        "\n",
        "plt.annotate('', xy=(-2, 0), xytext=(2, 0),size=15,\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "\n",
        "\n",
        "plt.annotate('[', xy=(-1, -0.01), xytext=(-1, -0.02))\n",
        "plt.annotate(']', xy=(1, -0.01), xytext=(1, -0.02))\n",
        "\n",
        "plt.annotate(r'$\\mu$', xy=(2, 0), xytext=(2, 0))\n",
        "\n",
        "plt.annotate('|', xy=(0, -0.01), xytext=(0, -0.02))\n",
        "\n",
        "plt.text(0.05, -0.35, r'$\\bar{X}$', ha='center', va='bottom', color='black')\n",
        "\n",
        "plt.text(-1, 0.1, r'$\\bar{X}-EM$', ha='center', va='bottom', color='black')\n",
        "plt.text(1, 0.1, r'$\\bar{X}+EM$', ha='center', va='bottom', color='black')\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-1, -0.5), xytext=(-2, -0.5),size=2,\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='|-|'))\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(1, -0.5), xytext=(2, -0.5),size=2,\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='|-|'))\n",
        "\n",
        "plt.text(0, -0.6, 'Intervalo de confianza', ha='center', va='bottom', color='black')\n",
        "\n",
        "# Establece los l√≠mites del gr√°fico\n",
        "plt.xlim(-3, 3)\n",
        "plt.ylim(-1, 1)\n",
        "\n",
        "# Muestra el gr√°fico\n",
        "plt.axis('off')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ClFfgIbFxhzh",
        "cellView": "form"
      },
      "id": "ClFfgIbFxhzh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intervalo de confianza para la proporci√≥n\n",
        "\n",
        "Para obtener el intervalo de confianza para la proporci√≥n $p$ con nivel de confianza $1-\\alpha$ usamos que, si se dan las condiciones de validez, se tiene\n",
        "\n",
        "$$\\frac{\\hat{p}-p}{\\sqrt{\\frac{p(1-p)}{n}}}\\thicksim N(0,1)$$\n",
        "\n",
        "\n",
        "Por lo tanto,\n",
        "\n",
        "$$1-\\alpha=P\\Big(-z_{\\alpha/2} < \\frac{\\hat{p}-p}{\\sqrt{\\frac{p(1-p)}{n}}} < z_{\\alpha/2}\\Big)$$\n",
        "\n",
        "Se despeja $p$. Para simplificar, si $n$ es grande ($n\\geq30$), suponemos que $\\hat{p}\\approx p$, de manera que la probabilidad anterior sea pr√°cticamente igual si sustituimos en el denominador $p(1-p)$ por $\\hat{p}(1-\\hat{p})$ y llamemos a $EM = z_{\\alpha/2}\\sqrt{\\hat{p}(1-\\hat{p}/n)}$ error muestral, es decir,\n",
        "\n",
        "\\begin{align*}\n",
        "    1-\\alpha&=P(-EM < \\hat{p}-p < EM)\\\\\n",
        "    &=P(\\hat{p}-EM < p < \\hat{p}+EM)\\\\\n",
        "    &=P(p\\in(\\hat{p}-EM,\\hat{p}+EM))    \n",
        "\\end{align*}\n",
        "\n",
        "Por lo tanto el intervalo de confianza para la proporci√≥n  $p$ con una fiabilidad del $1-\\alpha\\times100\\%$ es:\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "    IC_{1-\\alpha}&=\\Big(\\hat{p}-z_{\\alpha/2}\\frac{\\sqrt{\\hat{p}(1-\\hat{p}}}{\\sqrt{n}},\\hat{p}+z_{\\alpha/2}\\frac{\\sqrt{\\hat{p}(1-\\hat{p}}}{\\sqrt{n}}\\Big)\\\\\n",
        "    &=\\Big( \\hat{p} \\pm z_{\\alpha/2}\\frac{\\sqrt{\\hat{p}(1-\\hat{p}}}{\\sqrt{n}} \\Big)\n",
        "\\end{align*}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KOWKxuWaVD9K"
      },
      "id": "KOWKxuWaVD9K"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea graficos intervalo para la proporci√≥n\n",
        "# Par√°metros\n",
        "n = 100  # Tama√±o de la muestra\n",
        "alpha = 0.05  # Nivel de confianza\n",
        "\n",
        "# C√°lculo de los valores cr√≠ticos de la distribuci√≥n normal est√°ndar\n",
        "z_left = -norm.ppf(1 - alpha / 2)\n",
        "z_right = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Definir el rango para la gr√°fica\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, 'b-')\n",
        "# Rellenar el √°rea bajo la curva\n",
        "plt.fill_between(x, y, where=(x >= -2) & (x <= 2), color='lightblue', alpha=0.5)\n",
        "\n",
        "# L√≠neas verticales y etiquetas\n",
        "plt.axvline(0, color='red', linestyle='--', linewidth=0.3)\n",
        "plt.axhline(0, color='blue', linestyle='--', linewidth=0.3)\n",
        "\n",
        "plt.axvline(z_left, color='red', linestyle='--')\n",
        "plt.text(z_left, -0.01, r'$-z_{\\alpha/2}$', ha='right', va='bottom', color='red')\n",
        "plt.axvline(z_right, color='red', linestyle='--')\n",
        "plt.text(z_right, -0.01, r'$z_{\\alpha/2}$', ha='left', va='bottom', color='red')\n",
        "\n",
        "plt.text(0, -0.01, '0', ha='center', va='bottom', color='black')\n",
        "plt.text(0, 0.25, r'$1-\\alpha$', ha='center', va='bottom', color='red')\n",
        "\n",
        "plt.text(-2.5, 0.25, r'$-\\alpha/2$', ha='center', va='bottom', color='red')\n",
        "plt.text(2.5, 0.25, r'$\\alpha/2$', ha='center', va='bottom', color='red')\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.25), xytext=(2, 0.25),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.25), xytext=(-3, 0.25),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-'))\n",
        "\n",
        "plt.annotate('', xy=(3, 0.25), xytext=(2, 0.25),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='-|>'))\n",
        "\n",
        "plt.title('Intervalo de Confianza para la Media')\n",
        "plt.grid(True)\n",
        "plt.axis('off')\n",
        "# Mostrar la gr√°fica\n",
        "plt.show()\n",
        "\n",
        "\n",
        "################################################\n",
        "################################################\n",
        "################################################\n",
        "################################################\n",
        "plt.figure(figsize=(6,2))\n",
        "\n",
        "plt.annotate('', xy=(-2, 0), xytext=(2, 0),size=15,\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "\n",
        "\n",
        "plt.annotate('[', xy=(-1, -0.01), xytext=(-1, -0.02))\n",
        "plt.annotate(']', xy=(1, -0.01), xytext=(1, -0.02))\n",
        "\n",
        "plt.annotate(r'$p$', xy=(2, 0), xytext=(2, 0))\n",
        "\n",
        "plt.annotate('|', xy=(0, -0.01), xytext=(0, -0.02))\n",
        "\n",
        "plt.text(0.05, -0.35, r'$\\hat{p}$', ha='center', va='bottom', color='black')\n",
        "\n",
        "plt.text(-1, 0.1, r'$\\hat{p}-EM$', ha='center', va='bottom', color='black')\n",
        "plt.text(1, 0.1, r'$\\hat{p}+EM$', ha='center', va='bottom', color='black')\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-1, -0.5), xytext=(-2, -0.5),size=2,\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='|-|'))\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(1, -0.5), xytext=(2, -0.5),size=2,\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='|-|'))\n",
        "\n",
        "plt.text(0, -0.6, 'Intervalo de confianza', ha='center', va='bottom', color='black')\n",
        "\n",
        "# Establece los l√≠mites del gr√°fico\n",
        "plt.xlim(-3, 3)\n",
        "plt.ylim(-1, 1)\n",
        "\n",
        "# Muestra el gr√°fico\n",
        "plt.axis('off')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2DoFUw_pfeeQ",
        "cellView": "form"
      },
      "id": "2DoFUw_pfeeQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contraste de hip√≥tesis\n",
        "\n",
        "Planteamos una afirmaci√≥n sobre la variable que estudiamos, la **hip√≥tesis nula** $H_{0}$. Para contrastarla tomamos una muestra $X_{1}, X_{2}, ..., X_{n}$ aleatoria e independiente.\n",
        "\n",
        "Un contraste de hip√≥tesis $H_{0}$ consiste en aplicar un **estad√≠stico** $T(X_{1}, X_{2}, ..., X_{n})$ y determinar, para el **nivel de significaci√≥n** $\\alpha >0$ una **regi√≥n de rechazo** $R(\\alpha)$ tal que, si $H_{0}$ fuese cierta, la probabilidad de que $T(X_{1}, X_{2}, ..., X_{n})$ tome su valor en $R(\\alpha)$ para una muestra aleatoria ser√≠a tan peque√±a como $\\alpha$. En tal caso, $T(X_{1}, X_{2}, ..., X_{n}) \\in R(\\alpha)$, rechazamos $H_{0}$ y nos quedamos con su opuesta, la **hip√≥tesis alternativa** $H_{1}$.\n",
        "\n",
        "Si en cambio $T(X_{1}, X_{2}, ..., X_{n}) \\notin R(\\alpha)$, o sea $T(X_{1}, X_{2}, ..., X_{n}) \\in R(\\alpha)^{c}=RA(\\alpha)$ (**la regi√≥n de aceptaci√≥n**), entonces aceptamos $H_{0}$ (o mejor dicho en rigor, no rechazamos $H_{0}$).\n",
        "\n",
        "En caso de rechazo decimos que tenemos evidencia estad√≠stica suficiente para hacerlo (depende del nivel de significaci√≥n) y en caso contrario no podemos rechazarla porque no tenemos esa evidencia. ***Pero tampoco la tenemos de que $H_{0}$ sea cierta, ¬°el contraste no sirve para demostrar $H_{0}$!***\n",
        "\n",
        "\n",
        "En muchos contrastes de hip√≥tesis es posible calcular el p-valor, un valor dado por la muestra tal que si es menor que $\\alpha$ entones se rechaza $H_{0}$.\n",
        "\n",
        "Cuando el $p-valor$ es pr√°cticamente nulo significa que nuestros datos contradicen muy claramente $H_{0}$. Esto es, tenemos evidencia estad√≠stica abrumadora en contra de $H_{0}$ y la rechazaremos con cualquier nivel de significaci√≥n razonable.\n"
      ],
      "metadata": {
        "id": "yUGrYAM4cIaA"
      },
      "id": "yUGrYAM4cIaA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contraste para la media\n",
        "\n",
        "El contraste (bilateral) de la media en una poblaci√≥n normal consiste en las hip√≥tesis\n",
        "$$H_{0}:  \\mu = \\mu_{}  \\hspace{0.5cm} \\text{frente a} \\hspace{0.5cm} H_{1}:  \\mu \\neq \\mu_{}$$\n",
        "con una muestra de tama√±o $n$, $X_{1}, X_{2}, ..., X_{n}$.\n",
        "\n",
        "\n",
        "**Condiciones de validez:**\n",
        "\n",
        "*   Para todo $i, X_{i} \\thicksim N(\\mu,\\sigma)$ independientes.\n",
        "\n",
        "    Aplicamos el estad√≠stico:\n",
        "\n",
        "    $$t_{obs}=\\frac{\\bar{X}-\\mu_{0}}{S_{x}/\\sqrt{n}}$$\n",
        "\n",
        "*   Si $H_{0}$ es cierta se tiene que  $t_{obs} \\thicksim t_{n-1}$\n",
        "($t_{obs}$ es una variable aleatoria que retorna un valor para cada muestra de tama√±o $n$).\n",
        "\n",
        "    Por ello, tomamos para un nivel de significaci√≥n $\\alpha>0$, cuya regi√≥n de rechazo es:\n",
        "\n",
        "    $$R(\\alpha)=(-\\infty, -t_{(n-1;\\alpha/2)}] \\cup [t_{(n-1;\\alpha/2)},+\\infty )$$\n",
        "\n",
        "    Por lo tanto, rechazamos $H_{0}$ si\n",
        "    \n",
        "    $$|t_{obs}| \\geq t_{(n-1;\\alpha/2)}$$\n",
        "\n",
        "    O sea, aceptamos (no rechazamos) $H_{0}$ si\n",
        "    \n",
        "    $$|t_{obs}| < t_{(n-1;\\alpha/2)}$$\n",
        "    \n",
        "    La regi√≥n de aceptaci√≥n (de no rechazo) vine dada por:\n",
        "\n",
        "    $$RA(\\alpha) = (-t_{(n-1;\\alpha/2)},t_{(n-1;\\alpha/2)})$$\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "A $t_{obs}$ se le denomina **valor observado** del contraste, y a $t_{(n-1;\\alpha/2)}$ se le llama **valor cr√≠tico** del contraste.\n",
        "\n",
        "\n",
        "***Observaci√≥n:***\n",
        "\n",
        "Otra forma de realizar el contraste:\n",
        "\n",
        "\\begin{align*}\n",
        "    t_{obs} \\in RA(\\alpha) &\\Leftrightarrow  -t_{(n-1;\\alpha/2)} < \\frac{\\bar{X}-\\mu_{0}}{S_{X}/\\sqrt{n}} < t_{(n-1;\\alpha/2)}\\\\\n",
        "    &\\Leftrightarrow \\bar{X} - \\mu_{0} < EM, \\text{ donde  }  EM= t_{n-1;\\alpha/2}S_{X}/\\sqrt{n} \\\\\n",
        "    &\\Leftrightarrow \\bar{X} -EM < \\mu_{0} < \\bar{X} +EM\\\\\n",
        "    &\\Leftrightarrow \\mu_{0} \\in IC_{1-\\alpha}(\\mu)\n",
        "\\end{align*}\n",
        "\n",
        "Esto es, aceptamos $H_{0}$ si y s√≥lo si la media a contrastar esta en el intervalo de confianza que nos proporciona la muestra, para el nivel de confianza $1-\\alpha$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eD-oj7oXpf6h"
      },
      "id": "eD-oj7oXpf6h"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea gr√°fico zona de rechazo/aceptaci√≥n para la media\n",
        "# Par√°metros\n",
        "n = 100  # Tama√±o de la muestra\n",
        "alpha = 0.05  # Nivel de confianza\n",
        "\n",
        "# C√°lculo de los valores cr√≠ticos de la distribuci√≥n t de Student\n",
        "t_left = -t.ppf(1 - alpha / 2, n - 1)\n",
        "t_right = t.ppf(1 - alpha / 2, n - 1)\n",
        "\n",
        "# Definir el rango para la gr√°fica\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = t.pdf(x, n - 1)\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, 'b-')\n",
        "# Rellenar el √°rea bajo la curva\n",
        "plt.fill_between(x, y, where=(x >= -2) & (x <= 2), color='lightblue', alpha=0.5)\n",
        "\n",
        "# L√≠neas verticales y etiquetas\n",
        "plt.axvline(0, color='red', linestyle='--', linewidth=0.3)\n",
        "\n",
        "plt.axhline(0, color='blue', linestyle='--', linewidth=0.3)\n",
        "\n",
        "plt.axvline(t_left, color='red', linestyle='--')\n",
        "plt.text(t_left, -0.01, r'$-t_{n-1,\\alpha/2}$', ha='right', va='bottom', color='red')\n",
        "plt.axvline(t_right, color='red', linestyle='--')\n",
        "plt.text(t_right, -0.01, r'$t_{n-1,\\alpha/2}$', ha='left', va='bottom', color='red')\n",
        "\n",
        "plt.text(0, -0.01, '0', ha='center', va='bottom', color='black')\n",
        "\n",
        "\n",
        "plt.text(-2.5, 0.3, r'$R(\\alpha)$', ha='center', va='bottom', color='red')\n",
        "\n",
        "\n",
        "plt.text(0, 0.06, r'$RA(\\alpha)$', ha='center', va='bottom', color='black')\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.05), xytext=(2, 0.05),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2.5, 0.30), xytext=(2.6, 0.255),\n",
        "             arrowprops=dict(facecolor='grey', arrowstyle='<|-',linestyle='dashed', linewidth=0.3))\n",
        "\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2.5, 0.30), xytext=(-2.5, 0.255),\n",
        "             arrowprops=dict(facecolor='grey', arrowstyle='<|-',linestyle='dashed', linewidth=0.3))\n",
        "\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.25), xytext=(-3, 0.25),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='<|-',color='red'))\n",
        "\n",
        "plt.annotate('', xy=(3, 0.25), xytext=(2, 0.25),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='-|>',color='red'))\n",
        "\n",
        "plt.axis('off')\n",
        "# Mostrar la gr√°fica\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ILiewutLbQCe",
        "cellView": "form"
      },
      "id": "ILiewutLbQCe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El $p-valor$ para este contraste mide la probabilidad de que el estad√≠stico $t_{obs}$ se aleje de $0$ al menos una cantidad $|t_{obs}|$, esto es, dado $T \\thicksim t_{n-1}$\n",
        "\n",
        "\n",
        "$$p-valor = P(|T| > |t_{obs}|) = 2P(T > |t_{obs}|)$$\n",
        "\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "    \\text{Rechazamos} H_{0} & \\Leftrightarrow p-valor = 2P(T > |t_{obs}|) \\leq \\alpha\\\\\n",
        "    & \\Leftrightarrow P(T > |t_{obs}| )\\leq \\frac{\\alpha}{2}\\\\\n",
        "    & \\Leftrightarrow t_{n-1;\\alpha/2} \\leq |t_{obs}|\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "weFAydFzG6Z2"
      },
      "id": "weFAydFzG6Z2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contraste para la proporci√≥n\n",
        "\n",
        "En el contraste (bilateral) de la proporci√≥n se contrasta $p_{0}$ como valor de la proporci√≥n $p$, esto es:\n",
        "\n",
        "\\begin{cases}\n",
        "    H_{0}: p= p_{0}\\\\\n",
        "    H_{1}: p \\neq p_{0}\n",
        "\\end{cases}\n",
        "\n",
        "***Condiciones de validez:***\n",
        "\n",
        "*   La muestra es independiente y representativa de la poblaci√≥n\n",
        "*   $n \\geq 0$, o bien\n",
        "    \\begin{cases}\n",
        "        n\\hat{p} = k \\geq 5\\\\\n",
        "        n(1-\\hat{p}=n-k \\geq 5)\n",
        "    \\end{cases}\n",
        "\n",
        "El **valor observado** de contraste es el estad√≠stico $$Z_{obs}= \\frac{\\hat{p}-p_{0}}{\\sqrt{\\frac{p_{0}(1-p_{0})}{n}}}$$\n",
        "\n",
        "Si $H_{0}$ es cierta se tiene que $Z_{obs}$ se distribucye aproximadamente como una normal est√°ndar.\n",
        "Con esto, y fijando un nivel de significancia $\\alpha$, si ocurre $Z_{obs}\\geq Z_{\\alpha/2}$ o $Z_{obs}\\leq -Z_{\\alpha/2}$, entonces rechazamos $H_{0}$ (lo que implica quee no se considera fiabl que $p=p_{0}$, porque en tal caso ser√≠a muy extra√±o que la muestra fuera as√≠).\n",
        "\n",
        "\n",
        "La muestra est√° en la **regi√≥n de rechazo** $R(\\alpha) \\Leftrightarrow |Z_{obs}| \\geq Z_{\\alpha/2}$.\n",
        "\n",
        "La muestra est√° en la **regi√≥n de aceptaci√≥n**  $RA(\\alpha) \\Leftrightarrow Z_{obs} \\in (-Z_{\\alpha/2},Z_{\\alpha/2})$.\n",
        "\n",
        "Sea $Z \\thicksim N(0,1)$,\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "    \\text{Rechazamos } H_{0} & \\Leftrightarrow p-valor = P(|Z| > |Z_{obs}| )=2P(Z > |Z_{obs}|) \\leq \\alpha\\\\\n",
        "    & \\Leftrightarrow P(Z > |Z_{obs}| )\\leq \\frac{\\alpha}{2}\\\\\n",
        "    & \\Leftrightarrow Z_{\\alpha/2} \\leq |Z_{obs}|\n",
        "\\end{align*}\n"
      ],
      "metadata": {
        "id": "rkPJepkNJDZ6"
      },
      "id": "rkPJepkNJDZ6"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea gr√°fico zona de rechazo/aceptaci√≥n para la proporci√≥n\n",
        "# Par√°metros\n",
        "# Par√°metros\n",
        "n = 100  # Tama√±o de la muestra\n",
        "alpha = 0.05  # Nivel de confianza\n",
        "\n",
        "# C√°lculo de los valores cr√≠ticos de la distribuci√≥n normal est√°ndar\n",
        "z_left = -norm.ppf(1 - alpha / 2)\n",
        "z_right = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Definir el rango para la gr√°fica\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, 'b-')\n",
        "# Rellenar el √°rea bajo la curva\n",
        "plt.fill_between(x, y, where=(x >= -2) & (x <= 2), color='lightblue', alpha=0.5)\n",
        "\n",
        "# L√≠neas verticales y etiquetas\n",
        "plt.axvline(0, color='red', linestyle='--', linewidth=0.3)\n",
        "\n",
        "plt.axhline(0, color='blue', linestyle='--', linewidth=0.3)\n",
        "\n",
        "plt.axvline(t_left, color='red', linestyle='--')\n",
        "plt.text(t_left, -0.01, r'$-Z_{\\alpha/2}$', ha='right', va='bottom', color='red')\n",
        "plt.axvline(t_right, color='red', linestyle='--')\n",
        "plt.text(t_right, -0.01, r'$Z_{\\alpha/2}$', ha='left', va='bottom', color='red')\n",
        "\n",
        "plt.text(0, -0.01, '0', ha='center', va='bottom', color='black')\n",
        "\n",
        "\n",
        "plt.text(-2.5, 0.3, r'$R(\\alpha)$', ha='center', va='bottom', color='red')\n",
        "\n",
        "\n",
        "plt.text(0, 0.06, r'$RA(\\alpha)$', ha='center', va='bottom', color='black')\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.05), xytext=(2, 0.05),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='<|-|>'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2.5, 0.30), xytext=(2.6, 0.255),\n",
        "             arrowprops=dict(facecolor='grey', arrowstyle='<|-',linestyle='dashed', linewidth=0.3))\n",
        "\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2.5, 0.30), xytext=(-2.5, 0.255),\n",
        "             arrowprops=dict(facecolor='grey', arrowstyle='<|-',linestyle='dashed', linewidth=0.3))\n",
        "\n",
        "\n",
        "\n",
        "plt.annotate('', xy=(-2, 0.25), xytext=(-3, 0.25),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='<|-',color='red'))\n",
        "\n",
        "plt.annotate('', xy=(3, 0.25), xytext=(2, 0.25),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='-|>',color='red'))\n",
        "\n",
        "plt.axis('off')\n",
        "# Mostrar la gr√°fica\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DLOwzrkEBtII"
      },
      "id": "DLOwzrkEBtII",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consideraciones sobre la muestra:\n",
        "\n",
        "\n",
        "\n",
        "*   **Obtenci√≥n**: Debe ser independiente (los valores de cada caso no deben tener influencia en los dem√°s) y tambi√©n representativa (se necesita, para que la inferencia sea justificada, esperar que los valores de la muestra se asemejen en principio a los que se dan en toda la poblaci√≥n).\n",
        "\n",
        "*   **Tama√±o de la muestra**: Cuando calculamos un intervalo de confianza el grado de imprecisi√≥n lo da el error muestral. Obviamente, es menor cuanto mayor es el tama√±o de la muestra, pero puede ser impracticable (o tal vez car√≠simo) conseguir que el tama√±o sea muy grande. Lo que se hace es calcular el tama√±o que necesitar√≠amos para no rebasar un error muestral objetivo, y luego decidir en consecuencia.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1Pjf52tSNZO6"
      },
      "id": "1Pjf52tSNZO6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tama√±o de la muestra para la media\n",
        "\n",
        "En la inferencia sobre la media de una poblaci√≥n normal vimos que el error muestral se calcula\n",
        "$$EM= t_{n-1;\\alpha/2}\\frac{S_{X}}{n}$$\n",
        "\n",
        "Llamamos $EM_{obj}$ a nuestro objetivo y necesitamos que\n",
        "\n",
        "$$t_{n-1;\\alpha/2}\\frac{S_{X}}{\\sqrt{n}} \\leq EM_{obj}$$\n",
        "\n",
        "Para poder *despejar* $n$ sustituimos $t_{n-1;\\alpha/2}$ por $Z_{\\alpha/2}$.\n",
        "Obviamente no tenemos $S_{X}$, por lo que tomamos $S$, ya sea la *cuasivarianza* t√≠pica de una muestra previa o alguna otra estimaci√≥n fiable de la desviaci√≥n t√≠pica poblacional.\n",
        "\n",
        "Buscamos entonces:\n",
        "\n",
        "$$Z_{\\alpha/2}\\frac{S}{\\sqrt{n}} \\leq EM_{obj} \\Leftrightarrow Z_{\\alpha/2}\\frac{S}{EM_{obj}} \\leq \\sqrt{n} \\Leftrightarrow n \\geq Z_{\\alpha/2}^{2}\\frac{S^{2}}{EM_{obj}^{2}}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "fKDZtWwBwlC6"
      },
      "id": "fKDZtWwBwlC6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tama√±o de la muestra para la proporci√≥n\n",
        "\n",
        "Vimos qu el error muestral para $IC_{1-\\alpha}(p)$ es:\n",
        "\n",
        "$$EM = z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n",
        "\n",
        "Nos planteamos dos situaciones:\n",
        "\n",
        "*   Hemos obtenido ya $\\hat{p}$ con una muestra y queremos calcular $n$ para conseguir un valor $EM_{obj}$ *(error muestral objetivo)* con la misma $\\hat{p}$.\n",
        "\n",
        "    Por lo tanto tenemos:\n",
        "\n",
        "    \n",
        "$$Z_{\\alpha/2}\\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{n}} \\leq EM_{obj} \\Leftrightarrow Z_{\\alpha/2}\\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{EM_{obj}} \\leq \\sqrt{n} \\Leftrightarrow n \\geq Z_{\\alpha/2}^{2}\\frac{\\hat{p}(1-\\hat{p})}{EM_{obj}^{2}}$$\n",
        "\n",
        "*   Queremos conseguir un valor $EM_{obj}$ independientemente de qu√© $\\hat{p}$ obtengamos.\n",
        "Entonces, cambiamos $\\hat{p}(1-\\hat{p})$ por su m√°ximo valor posible en $\\hat{p} \\in (0,1)$, que es cuando $\\hat{p}=1/2$, en cuyo caso, $\\hat{p}(1-\\hat{p})=1/4$.\n",
        "Tomamos entonces\n",
        "\n",
        "$$n \\geq Z_{\\alpha/2}^{2} \\frac{1}{4EM^{2}_{obj}}$$\n",
        "\n",
        "\n",
        "***NOTA:***\n",
        "\n",
        "En ambas situaciones, como nos basamos en la aproximaci√≥n a la distribuci√≥n normal est√°ndar de $$\\frac{\\hat{p}-p}{\\sqrt{\\frac{p(1-p)}{n}}}$$ para dar por bueno lo anterior, necesitamos obtener $n \\geq 30$.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cflJzc5d3GqD"
      },
      "id": "cflJzc5d3GqD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESUMEN:\n",
        "\n",
        "| Sobre la media                                                                 | Sobre la proporci√≥n                                                      |\n",
        "|--------------------------------------------------------------------------------|---------------------------------------------------------------------------|\n",
        "| - Intervalo de Confianza:                                                      | - Intervalo de confianza:                                                |\n",
        "|                                                                                  |                                                                           |\n",
        "| $$\\Big( \\bar{X} \\pm t_{n-1\\;\\alpha/2}\\frac{S_{X}}{\\sqrt{n}}\\Big)$$             | $$\\Big( \\hat{p} \\pm z_{\\alpha/2}\\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{n}} \\Big)$$ |\n",
        "|                                                                                  |                                                                           |\n",
        "| - Contraste de hip√≥tesis:                                                       | - Contraste de hip√≥tesis:                                                |\n",
        "|                                                                                  |                                                                           |\n",
        "| $$t_{obs}=\\frac{\\bar{X}-\\mu_{0}}{S_{x}/\\sqrt{n}},$$                            | $$Z_{obs}= \\frac{\\hat{p}-p_{0}}{\\sqrt{\\frac{p_{0}(1-p_{0})}{n}}},$$        |\n",
        "| $$RA(\\alpha) = (\\pm t_{(n-1;\\alpha/2)}),$$                                      | $$RA(\\alpha) = (\\pm Z_{\\alpha/2}),$$                                      |\n",
        "| $$p-valor = 2P(T > |t_{obs}|) \\text{ con } T \\thicksim t_{n-1}$$                | $$p-valor = 2P(Z > |Z_{obs}|) \\text{ con } Z \\thicksim N(0,1)$$           |\n",
        "|                                                                                  |                                                                           |\n",
        "| - Tama√±o de la muestra:                                                         | - Tama√±o de la muestra:                                                   |\n",
        "|                                                                                  |                                                                           |\n",
        "| $$n \\geq Z_{\\alpha/2}^{2} \\frac{S^{2}}{EM^{2}_{obj}}$$                         | - Con informaci√≥n muestral:                                              |\n",
        "|                                                                                  |                                                                           |\n",
        "|                                                                                  | $$n \\geq Z_{\\alpha/2}^{2}\\frac{\\hat{p}(1-\\hat{p})}{EM_{obj}^{2}}$$        |\n",
        "|                                                                                  |                                                                           |\n",
        "|                                                                                  | - Sin informaci√≥n adicional:                                              |\n",
        "|                                                                                  |                                                                           |\n",
        "|                                                                                  | $$n \\geq Z_{\\alpha/2}^{2} \\frac{1}{4EM^{2}_{obj}}$$                       |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9m4_LYJdAQYU"
      },
      "id": "9m4_LYJdAQYU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n"
      ],
      "metadata": {
        "id": "yJYm4ZiqQGtJ"
      },
      "id": "yJYm4ZiqQGtJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estad√≠stica Multivariante\n",
        "\n",
        "Estudiamos los datos, en $N$ casos, en primer lugar, de ***dos*** variables $X$ e $Y$. Queremos analizar la relaci√≥n entre ellas y medir el grado de asociaci√≥n detectada. En este contexto, la distribuci√≥n marginal de $X$ es la de dicha variable por s√≠ sola, sin tener en cuenta los valores de $Y$.\n",
        "\n",
        "*   **Datos cuantitativos:**\n",
        "    *   *Presentaci√≥n de los datos:* tabla de frecuencias de doble entrada.\n",
        "    *   *Relaci√≥n lineal y covarianza:* recta de regresi√≥n (con predicci√≥n), coeficiente de correlaci√≥n y coeficiente de determinaci√≥n.\n",
        "\n",
        "*   **Datos cualitativos:**\n",
        "    *   *Variables ordinales:* coeficiente de correlaci√≥n por rangos.\n",
        "    *   *Variables categ√≥ricas no ordinales:* tabla de contingencia y $Q$ de Yule.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PGMhC6C8QKeZ"
      },
      "id": "PGMhC6C8QKeZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tablas de frecuencia de doble entrada\n",
        "\n",
        "Se parte de dos variables $X$ e $y$ tomadas en $N$ casos. En las filas se indican los valores (o las marcas de clase de los intervalos) de $X$ y en las columnas los de $Y$. El valor de la fila $i$ y la columna $j$ es la frecuencia absoluta (n√∫mero de casos) que se sit√∫an en el $i$-√©simo valor (o intervalo) de $X$ y el $j$-√©simo de $Y : n_{ij}$.\n",
        "\n",
        "La tabla se completa a√±adiendo una nueva columna que refleja las frecuencias marginales de $X (n_{i}: \\text{ frecuencia absoluta del i-√©simo valor de } X)$, y una nueva fila con las frecuencias marginales de $Y (n_{j}: \\text{ frecuencia absoluta del j-√©simo valor de } Y)$\n",
        "\n",
        "Tambi√©n se pueden calcular las frecuencias relativas, aunque estas no se suelen ubicar en la tabla. Se calculan haciendo el cociente con la frecuencia total de casos:\n",
        "\n",
        "$$f_{ij}=\\frac{n_{ij}}{N}; f_{i}=\\frac{n_{i}}{N}; f_{j}=\\frac{n_{j}}{N} $$\n",
        "\n",
        "\n",
        "Esta informaci√≥n puede ser presentada en formato largo por columnas, donde cada fila recoge el par $x_{i}$ e $y_{i}$ junto con su frecuencia $n_{ij}$.\n"
      ],
      "metadata": {
        "id": "gDbKlHqNSK9q"
      },
      "id": "gDbKlHqNSK9q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo:\n",
        "\n",
        "<!-- **Objetivo**: Teniendo en cuenta el texto que venimos trabajando, construir una tabla de frecuencias de doble entrada para analizar la relaci√≥n entre el n√∫mero de palabras con longitud $\\geq 10$ y el n√∫mero de palabras que comienzan con la letra $e$\n",
        "\n",
        "\n",
        "**Variables**:\n",
        "\n",
        "*   **Variable X**: N√∫mero de palabras .\n",
        "\n",
        "*   **Variable Y**: Longitud del texto de la rese√±a (N√∫mero de palabras utilizadas). -->\n"
      ],
      "metadata": {
        "id": "LZCRfL_MaFuM"
      },
      "id": "LZCRfL_MaFuM"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dividir el texto en palabras\n",
        "# palabras = texto_limpio.split()\n",
        "\n",
        "# # Contar palabras con longitud mayor o igual a 10 caracteres\n",
        "# num_palabras_largas = sum(1 for palabra in palabras if len(palabra) >= 10)\n",
        "\n",
        "# # Contar palabras que comienzan con \"e\" y tienen longitud mayor o igual a 10 caracteres\n",
        "# num_palabras_e_largas = sum(1 for palabra in palabras if len(palabra) >= 10 and palabra.lower().startswith('e'))\n",
        "\n",
        "# # Calcular la probabilidad condicionada\n",
        "# probabilidad_condicionada = num_palabras_e_largas / num_palabras_largas\n",
        "\n",
        "# print(\"N√∫mero total de palabras con longitud mayor o igual a 10:\", num_palabras_largas)\n",
        "# print(\"N√∫mero de palabras que comienzan con 'e' y tienen longitud mayor o igual a 10:\", num_palabras_e_largas)\n",
        "# print(\"Probabilidad de que una palabra comience con 'e' dado que tiene longitud mayor o igual a 10:\", probabilidad_condicionada)"
      ],
      "metadata": {
        "id": "ajVaJppQPPL_"
      },
      "id": "ajVaJppQPPL_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Covarianza\n",
        "\n",
        "La **covarianza** entre $X$ e $Y$ (de manera que $X_{i}$ e $Y_{i}$ son, respectivamente, los valores de $X$ e $Y$ en cada caso $i=1, 2, ..., N$) es:\n",
        "\n",
        "$$cov(X,Y)= S_{X,Y}=\\frac{1}{N} \\sum_{i=1}^{N}(X_{i}-\\bar{X})(Y_{i}-\\bar{Y}).$$\n",
        "\n",
        "Operando se puede observar que la covarianza es igual a la media del producto menos el producto de las medias, que deriva en la expresi√≥n que depende de las sumas, esto es:\n",
        "\n",
        "$$cov(X,Y)=\\overline{X.Y}-\\bar{X}-\\bar{Y}= \\frac{1}{N}\\Big[\\sum_{i=1}^{N}(X_{i}Y_{i})-\\frac{(\\sum_{i=1}^{N}X_{i})(\\sum_{i=1}^{N}Y_{i})}{N}\\Big]$$\n",
        "\n",
        "***Observaci√≥n:***\n",
        "\n",
        "La covarianza de una variable consigo misma es la varianza de la variable:\n",
        "\n",
        "$$cov(X,X)= S_{X,X}=\\frac{1}{N} \\sum_{i=1}^{N}(X_{i}-\\bar{X})(X_{i}-\\bar{Y})=\\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\bar{X})^{2}=S_{x}^{2}$$\n",
        "\n",
        "### Ejercicio:"
      ],
      "metadata": {
        "id": "4ZxqENCWNhVx"
      },
      "id": "4ZxqENCWNhVx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretaci√≥n de la covarianza:\n",
        "\n",
        "La expresi√≥n de la definici√≥n es √∫til para entender el significado del signo de la covarianza:\n",
        "\n",
        "*   $cov(X,Y)>0$: Si a valores grandes de $X$ les corresponden valores grandes de $Y$ e √≠dem peque√±os-peque√±os, entonces en los sumandos de la definici√≥n $X_{i}-\\bar{X}$ e $Y_{i}-\\bar{Y}$ normalmente tienen el mismo signo y su producto es positivo, luego predominan los sumandos positivos. Si las frecuencias m√°s altas se dan en la diagonal descendente de la tabla de doble entrada, se intuye que la covarianza ser√° positiva.\n",
        "\n",
        "\n",
        "*   $cov(X,Y)< 0$: Si a valores grandes de $X$ les corresponden valores peque√±os de $Y$ y viceversa. Predominan los sumandos negativos porque los signos de $X_{i}-\\bar{X}$ e $Y_{i}-\\bar{Y}$ normalmente son opuestos. Si las frecuencias m√°s altas se dan en la diagonal ascendente de la tabla de doble entrada, se espera que la covarianza sea negativa.\n"
      ],
      "metadata": {
        "id": "oO8oriqVQ8Pl"
      },
      "id": "oO8oriqVQ8Pl"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Crea gr√°fico signo de la covarianza\n",
        "# Crear una nueva figura y ejes con dos subgr√°ficos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Para el primer subgr√°fico\n",
        "ax1.plot([0, 1], [0, 1], color='blue')  # L√≠nea diagonal descendente\n",
        "ax1.set_title('Diagonal descendente')\n",
        "\n",
        "# Para el segundo subgr√°fico\n",
        "ax2.plot([0, 1], [1, 0], color='blue')  # L√≠nea diagonal ascendente\n",
        "ax2.set_title('Diagonal ascendente')\n",
        "\n",
        "# Ajustar los l√≠mites de los ejes para ambos subgr√°ficos\n",
        "for ax in (ax1, ax2):\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_aspect('equal', 'box')\n",
        "\n",
        "# Mostrar el gr√°fico\n",
        "plt.tight_layout()\n",
        "ax1.set_xticks([])\n",
        "ax1.set_yticks([])\n",
        "ax2.set_xticks([])\n",
        "ax2.set_yticks([])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "VR4asj_OawsM",
        "cellView": "form"
      },
      "id": "VR4asj_OawsM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Propiedades de la covarianza\n",
        "\n",
        "\n",
        "**Propiedades**. La covarianza es independiente del orden de las variables, no le afectan los cambios de origen, pero s√≠ los de escala. Dadas $X$ e $Y$ variables tomadas sobre los mismos casos; las constantes a, b, c y d; y las variables transformadas $U=a+bX$ $V=c+dY$. Se cumplen las siguientes igualdades:\n",
        "\n",
        "\n",
        "\n",
        "*   cov(X,Y) = cov(Y,X)\n",
        "*   cov(U,Y) = cov(a+bX,Y) = b cov(X,Y)\n",
        "*   cov(X,V) = cov(X,c+dY) = d cpv (X,Y)\n",
        "*   cov(U,V) = cov(a+bX,c+dY) = bc cov (X,Y)\n",
        "\n",
        "\n",
        "\n",
        "La **cuasicovarianza** se define de manera an√°loga a la cuasivarianza y resulta:\n",
        "\n",
        "\n",
        "$$S_{X,Y}= \\frac{1}{}N-1\\sum_{i=1}^{N}(X_{i}-\\bar{X})(Y_{i}-\\bar{Y})=\\frac{1}{N-1}\\Big[  \\sum_{i=1}^{N} (X_{i}Y_{i})-\\frac{(\\sum_{i=1}^{N}X_{i})(\\sum_{i=1}^{N}Y_{i})}{N} \\Big] = \\frac{N}{N-1}S_{X,Y}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "Cq3dDWD6TmeB"
      },
      "id": "Cq3dDWD6TmeB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresi√≥n Lineal\n",
        "\n",
        "Sean las variables $X$ e $Y$ (de manera que $X_{i}$ e $Y_{i}$ son, respectivamente, los valores de $X$ e $Y$ en cada caso $i=1,...,N$), la **recta de regresi√≥n** $r_{Y|X}$ es la recta $Y^{*}=a+bX$ para la que es m√≠nimo\n",
        "\n",
        "$$\\sum_{i=1}^{N}e_{i}^{2}=\\sum_{i=1}^{N}(Y_{i}^{*}-Y_{i})^{2}=\\sum_{i=1}^{N}(a+bX_{i}-Y_{i})^{2}$$\n",
        "\n",
        "Esto se consigue tomando los valores\n",
        "\n",
        "$$b=\\frac{S_{X,Y}}{S_{X}^{2}},$$\n",
        "\n",
        "y $$a=\\bar{Y}-b\\bar{X},$$\n",
        "\n",
        "por lo tanto, $\\bar{Y}=a+b\\bar{X}$, esto es, la recta pasa por el punto $(\\bar{X},\\bar{Y}).$\n",
        "\n",
        "Se denota $r_{Y|X}\\equiv a+bX$. A $X$ se le denomina la **variaable explicaativa**, e $Y$ es la **variable explicada**.\n",
        "\n",
        "\n",
        "**Ejercicio.**"
      ],
      "metadata": {
        "id": "NerYu_-NvR5B"
      },
      "id": "NerYu_-NvR5B"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K2EJh88ZSDOO"
      },
      "id": "K2EJh88ZSDOO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}